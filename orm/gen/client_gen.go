// Code generated by erm. DO NOT EDIT.
package gen

import (
	"context"
	"errors"
	"fmt"
	"github.com/deicod/erm/orm/id"
	"github.com/deicod/erm/orm/pg"
	"github.com/deicod/erm/orm/runtime"
	"github.com/deicod/erm/orm/runtime/cache"
	"github.com/deicod/erm/orm/runtime/validation"
	"github.com/jackc/pgx/v5"
	"strings"
	"time"
)

var ValidationRegistry = validation.NewRegistry()

type Client struct {
	db    *pg.DB
	cache cache.Store
}

func NewClient(db *pg.DB) *Client {
	return &Client{db: db, cache: cache.Nop()}
}

func (c *Client) UseCache(store cache.Store) {
	if c == nil {
		return
	}
	if store == nil {
		store = cache.Nop()
	}
	c.cache = store
}

func (c *Client) cacheStore() cache.Store {
	if c == nil || c.cache == nil {
		return cache.Nop()
	}
	return c.cache
}

func makeCacheKey(entity string, id any) string {
	return "orm:" + entity + ":" + fmt.Sprint(id)
}

func (c *Client) Categories() *CategoryClient {
	return &CategoryClient{db: c.db, cache: c.cacheStore()}
}

func (c *Client) Comments() *CommentClient {
	return &CommentClient{db: c.db, cache: c.cacheStore()}
}

func (c *Client) Medias() *MediaClient {
	return &MediaClient{db: c.db, cache: c.cacheStore()}
}

func (c *Client) Options() *OptionClient {
	return &OptionClient{db: c.db, cache: c.cacheStore()}
}

func (c *Client) Posts() *PostClient {
	return &PostClient{db: c.db, cache: c.cacheStore()}
}

func (c *Client) Roles() *RoleClient {
	return &RoleClient{db: c.db, cache: c.cacheStore()}
}

func (c *Client) Tags() *TagClient {
	return &TagClient{db: c.db, cache: c.cacheStore()}
}

func (c *Client) Users() *UserClient {
	return &UserClient{db: c.db, cache: c.cacheStore()}
}

const categoryInsertQuery = `INSERT INTO categories (id, name, slug, description, parent_id, created_at, updated_at) VALUES ($1, $2, $3, $4, $5, $6, $7) RETURNING id, name, slug, description, parent_id, created_at, updated_at`
const categorySelectQuery = `SELECT id, name, slug, description, parent_id, created_at, updated_at FROM categories WHERE id = $1`
const categoryListQuery = `SELECT id, name, slug, description, parent_id, created_at, updated_at FROM categories ORDER BY id LIMIT $1 OFFSET $2`
const categoryUpdateQuery = `UPDATE categories SET name = $1, slug = $2, description = $3, parent_id = $4, updated_at = $5 WHERE id = $6 RETURNING id, name, slug, description, parent_id, created_at, updated_at`
const categoryCountQuery = `SELECT COUNT(*) FROM categories`
const categoryDeleteQuery = `DELETE FROM categories WHERE id = $1`

type CategoryClient struct {
	db    *pg.DB
	cache cache.Store
}

func (c *CategoryClient) Create(ctx context.Context, input *Category) (*Category, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	now := time.Now().UTC()
	if input.ID == "" {
		v, err := id.NewV7()
		if err != nil {
			return nil, err
		}
		input.ID = v
	}
	if input.CreatedAt.IsZero() {
		input.CreatedAt = now
	}
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Category", validation.OpCreate, categoryValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, categoryInsertQuery, input.ID, input.Name, input.Slug, input.Description, input.ParentID, input.CreatedAt, input.UpdatedAt)
	out := new(Category)
	if err := row.Scan(&out.ID, &out.Name, &out.Slug, &out.Description, &out.ParentID, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Category", out.ID), out)
	}
	return out, nil
}

func (c *CategoryClient) BulkCreate(ctx context.Context, inputs []*Category) ([]*Category, error) {
	if len(inputs) == 0 {
		return []*Category{}, nil
	}
	rowsSpec := make([][]any, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		now := time.Now().UTC()
		if input.ID == "" {
			v, err := id.NewV7()
			if err != nil {
				return nil, err
			}
			input.ID = v
		}
		if input.CreatedAt.IsZero() {
			input.CreatedAt = now
		}
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Category", validation.OpCreate, categoryValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := []any{input.ID, input.Name, input.Slug, input.Description, input.ParentID, input.CreatedAt, input.UpdatedAt}
		rowsSpec = append(rowsSpec, row)
	}
	spec := runtime.BulkInsertSpec{
		Table:     "categories",
		Columns:   []string{"id", "name", "slug", "description", "parent_id", "created_at", "updated_at"},
		Returning: []string{"id", "name", "slug", "description", "parent_id", "created_at", "updated_at"},
		Rows:      rowsSpec,
	}
	sql, args, err := runtime.BuildBulkInsertSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var created []*Category
	for rows.Next() {
		item := new(Category)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.ParentID, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		created = append(created, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Category", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return created, nil
}

func (c *CategoryClient) ByID(ctx context.Context, id string) (*Category, error) {
	var cachedKey string
	if c.cache != nil {
		cachedKey = makeCacheKey("Category", id)
		if value, ok, err := c.cache.Get(ctx, cachedKey); err != nil {
			return nil, err
		} else if ok {
			if entity, ok := value.(*Category); ok {
				return entity, nil
			}
		}
	}
	row := c.db.Pool.QueryRow(ctx, categorySelectQuery, id)
	out := new(Category)
	if err := row.Scan(&out.ID, &out.Name, &out.Slug, &out.Description, &out.ParentID, &out.CreatedAt, &out.UpdatedAt); err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, nil
		}
		return nil, err
	}
	if c.cache != nil {
		cachedKey = makeCacheKey("Category", out.ID)
		_ = c.cache.Set(ctx, cachedKey, out)
	}
	return out, nil
}

func (c *CategoryClient) List(ctx context.Context, limit, offset int) ([]*Category, error) {
	if limit <= 0 {
		limit = 20
	}
	if offset < 0 {
		offset = 0
	}
	rows, err := c.db.Pool.Query(ctx, categoryListQuery, limit, offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Category
	for rows.Next() {
		item := new(Category)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.ParentID, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (c *CategoryClient) Count(ctx context.Context) (int, error) {
	row := c.db.Pool.QueryRow(ctx, categoryCountQuery)
	var total int
	if err := row.Scan(&total); err != nil {
		return 0, err
	}
	return total, nil
}

func (c *CategoryClient) Update(ctx context.Context, input *Category) (*Category, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	if input.ID == "" {
		return nil, errors.New("id is required")
	}
	now := time.Now().UTC()
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Category", validation.OpUpdate, categoryValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, categoryUpdateQuery, input.Name, input.Slug, input.Description, input.ParentID, input.UpdatedAt, input.ID)
	out := new(Category)
	if err := row.Scan(&out.ID, &out.Name, &out.Slug, &out.Description, &out.ParentID, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Category", out.ID), out)
	}
	return out, nil
}

func (c *CategoryClient) BulkUpdate(ctx context.Context, inputs []*Category) ([]*Category, error) {
	if len(inputs) == 0 {
		return []*Category{}, nil
	}
	specs := make([]runtime.BulkUpdateRow, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		if input.ID == "" {
			return nil, errors.New("id is required")
		}
		now := time.Now().UTC()
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Category", validation.OpUpdate, categoryValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := runtime.BulkUpdateRow{
			Primary: input.ID,
			Values:  []any{input.Name, input.Slug, input.Description, input.ParentID, input.UpdatedAt},
		}
		specs = append(specs, row)
	}
	spec := runtime.BulkUpdateSpec{
		Table:         "categories",
		PrimaryColumn: "id",
		Columns:       []string{"name", "slug", "description", "parent_id", "updated_at"},
		Returning:     []string{"id", "name", "slug", "description", "parent_id", "created_at", "updated_at"},
		Rows:          specs,
	}
	sql, args, err := runtime.BuildBulkUpdateSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var updated []*Category
	for rows.Next() {
		item := new(Category)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.ParentID, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		updated = append(updated, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Category", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return updated, nil
}

func (c *CategoryClient) Delete(ctx context.Context, id string) error {
	if _, err := c.db.Pool.Exec(ctx, categoryDeleteQuery, id); err != nil {
		return err
	}
	if c.cache != nil {
		_ = c.cache.Delete(ctx, makeCacheKey("Category", id))
	}
	return nil
}

func (c *CategoryClient) BulkDelete(ctx context.Context, ids []string) (int64, error) {
	if len(ids) == 0 {
		return 0, nil
	}
	spec := runtime.BulkDeleteSpec{
		Table:         "categories",
		PrimaryColumn: "id",
		IDs:           make([]any, len(ids)),
	}
	for i, id := range ids {
		spec.IDs[i] = id
	}
	sql, args, err := runtime.BuildBulkDeleteSQL(spec)
	if err != nil {
		return 0, err
	}
	tag, err := c.db.Pool.Exec(ctx, sql, args...)
	if err != nil {
		return 0, err
	}
	if c.cache != nil {
		for _, id := range ids {
			_ = c.cache.Delete(ctx, makeCacheKey("Category", id))
		}
	}
	return int64(tag.RowsAffected()), nil
}

type CategoryQuery struct {
	db           *pg.DB
	predicates   []runtime.Predicate
	orders       []runtime.Order
	limit        *int
	offset       int
	defaultLimit int
	maxLimit     int
}

func (c *CategoryClient) Query() *CategoryQuery {
	return &CategoryQuery{db: c.db, defaultLimit: 100, maxLimit: 500}
}

func (q *CategoryQuery) Limit(n int) *CategoryQuery {
	if n <= 0 {
		q.limit = nil
		return q
	}
	q.limit = &n
	return q
}

func (q *CategoryQuery) Offset(n int) *CategoryQuery {
	if n < 0 {
		return q
	}
	q.offset = n
	return q
}

func (q *CategoryQuery) WhereIDEq(value string) *CategoryQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "id", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *CategoryQuery) WhereSlugEq(value string) *CategoryQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "slug", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *CategoryQuery) WhereParentIDEq(value string) *CategoryQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "parent_id", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *CategoryQuery) OrderByNameAsc() *CategoryQuery {
	q.orders = append(q.orders, runtime.Order{Column: "name", Direction: runtime.SortAsc})
	return q
}

func (q *CategoryQuery) All(ctx context.Context) ([]*Category, error) {
	spec := runtime.SelectSpec{
		Table:      "categories",
		Columns:    []string{"id", "name", "slug", "description", "parent_id", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Category
	for rows.Next() {
		item := new(Category)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.ParentID, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (q *CategoryQuery) Stream(ctx context.Context) (*runtime.Stream[*Category], error) {
	spec := runtime.SelectSpec{
		Table:      "categories",
		Columns:    []string{"id", "name", "slug", "description", "parent_id", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	stream := runtime.NewStream[*Category](rows, func(rows pgx.Rows) (*Category, error) {
		item := new(Category)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.ParentID, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		return item, nil
	})
	return stream, nil
}

func (q *CategoryQuery) First(ctx context.Context) (*Category, error) {
	clone := q.clone()
	one := 1
	clone.limit = &one
	items, err := clone.All(ctx)
	if err != nil {
		return nil, err
	}
	if len(items) == 0 {
		return nil, nil
	}
	return items[0], nil
}

func (q *CategoryQuery) Count(ctx context.Context) (int, error) {
	spec := runtime.AggregateSpec{
		Table:      "categories",
		Predicates: q.predicates,
		Aggregate:  runtime.Aggregate{Func: runtime.AggCount, Column: "*"},
	}
	row := q.db.Aggregate(ctx, spec)
	var out int
	if err := row.Scan(&out); err != nil {
		return out, err
	}
	return out, nil
}

func (q *CategoryQuery) clone() *CategoryQuery {
	cp := *q
	if len(q.predicates) > 0 {
		cp.predicates = append([]runtime.Predicate(nil), q.predicates...)
	}
	if len(q.orders) > 0 {
		cp.orders = append([]runtime.Order(nil), q.orders...)
	}
	if q.limit != nil {
		limit := *q.limit
		cp.limit = &limit
	}
	return &cp
}

func (q *CategoryQuery) effectiveLimit() int {
	if q.limit != nil {
		limit := *q.limit
		if q.maxLimit > 0 && limit > q.maxLimit {
			return q.maxLimit
		}
		return limit
	}
	limit := q.defaultLimit
	if limit <= 0 && q.maxLimit > 0 {
		return q.maxLimit
	}
	if q.maxLimit > 0 && limit > q.maxLimit {
		return q.maxLimit
	}
	return limit
}

const categoryParentRelationQuery = `SELECT id, name, slug, description, parent_id, created_at, updated_at FROM categories WHERE id IN (%s)`

func (c *CategoryClient) LoadParent(ctx context.Context, parents ...*Category) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureCategoryEdges(parent)
		edges.markLoaded("parent")
		var fk keyType
		fkPtr := parent.ParentID
		if fkPtr == nil {
			edges.Parent = nil
			continue
		}
		fk = *fkPtr
		if isZero(fk) {
			edges.Parent = nil
			continue
		}
		if _, ok := seen[fk]; !ok {
			seen[fk] = struct{}{}
			keys = append(keys, fk)
		}
	}
	if len(keys) == 0 {
		return nil
	}
	sql, args := buildInQuery(categoryParentRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	related := make(map[keyType]*Category, len(keys))
	for rows.Next() {
		item := new(Category)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.ParentID, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return err
		}
		key := item.ID
		related[key] = item
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureCategoryEdges(parent)
		var fk keyType
		fkPtr := parent.ParentID
		if fkPtr == nil {
			edges.Parent = nil
			continue
		}
		fk = *fkPtr
		if isZero(fk) {
			edges.Parent = nil
			continue
		}
		if item, ok := related[fk]; ok {
			edges.Parent = item
		} else {
			edges.Parent = nil
		}
	}
	return nil
}

const categoryPostsRelationQuery = `SELECT id, author_id, featured_media_id, title, slug, status, type, excerpt, content, seo, published_at, created_at, updated_at, jt.category_id FROM posts AS t JOIN post_categories AS jt ON t.id = jt.post_id WHERE jt.category_id IN (%s)`

func (c *CategoryClient) LoadPosts(ctx context.Context, parents ...*Category) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	buckets := make(map[keyType][]*Category, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		key := parent.ID
		if isZero(key) {
			edges := ensureCategoryEdges(parent)
			if edges.Posts == nil {
				edges.Posts = []*Post{}
			}
			edges.markLoaded("posts")
			continue
		}
		if _, ok := seen[key]; !ok {
			seen[key] = struct{}{}
			keys = append(keys, key)
		}
		buckets[key] = append(buckets[key], parent)
	}
	if len(keys) == 0 {
		for _, parent := range parents {
			if parent == nil {
				continue
			}
			edges := ensureCategoryEdges(parent)
			if edges.Posts == nil {
				edges.Posts = []*Post{}
			}
			edges.markLoaded("posts")
		}
		return nil
	}
	sql, args := buildInQuery(categoryPostsRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	for rows.Next() {
		item := new(Post)
		var owner keyType
		if err := rows.Scan(&item.ID, &item.AuthorID, &item.FeaturedMediaID, &item.Title, &item.Slug, &item.Status, &item.Type, &item.Excerpt, &item.Content, &item.Seo, &item.PublishedAt, &item.CreatedAt, &item.UpdatedAt, &owner); err != nil {
			return err
		}
		parents, ok := buckets[owner]
		if !ok {
			continue
		}
		for _, parent := range parents {
			edges := ensureCategoryEdges(parent)
			edges.Posts = append(edges.Posts, item)
		}
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureCategoryEdges(parent)
		if edges.Posts == nil {
			edges.Posts = []*Post{}
		}
		edges.markLoaded("posts")
	}
	return nil
}

const commentInsertQuery = `INSERT INTO comments (id, post_id, author_id, parent_id, author_name, author_email, author_url, content, status, submitted_at, published_at, updated_at) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12) RETURNING id, post_id, author_id, parent_id, author_name, author_email, author_url, content, status, submitted_at, published_at, updated_at`
const commentSelectQuery = `SELECT id, post_id, author_id, parent_id, author_name, author_email, author_url, content, status, submitted_at, published_at, updated_at FROM comments WHERE id = $1`
const commentListQuery = `SELECT id, post_id, author_id, parent_id, author_name, author_email, author_url, content, status, submitted_at, published_at, updated_at FROM comments ORDER BY id LIMIT $1 OFFSET $2`
const commentUpdateQuery = `UPDATE comments SET post_id = $1, author_id = $2, parent_id = $3, author_name = $4, author_email = $5, author_url = $6, content = $7, status = $8, published_at = $9, updated_at = $10 WHERE id = $11 RETURNING id, post_id, author_id, parent_id, author_name, author_email, author_url, content, status, submitted_at, published_at, updated_at`
const commentCountQuery = `SELECT COUNT(*) FROM comments`
const commentDeleteQuery = `DELETE FROM comments WHERE id = $1`

type CommentClient struct {
	db    *pg.DB
	cache cache.Store
}

func (c *CommentClient) Create(ctx context.Context, input *Comment) (*Comment, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	now := time.Now().UTC()
	if input.ID == "" {
		v, err := id.NewV7()
		if err != nil {
			return nil, err
		}
		input.ID = v
	}
	if input.SubmittedAt.IsZero() {
		input.SubmittedAt = now
	}
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Comment", validation.OpCreate, commentValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, commentInsertQuery, input.ID, input.PostID, input.AuthorID, input.ParentID, input.AuthorName, input.AuthorEmail, input.AuthorURL, input.Content, input.Status, input.SubmittedAt, input.PublishedAt, input.UpdatedAt)
	out := new(Comment)
	if err := row.Scan(&out.ID, &out.PostID, &out.AuthorID, &out.ParentID, &out.AuthorName, &out.AuthorEmail, &out.AuthorURL, &out.Content, &out.Status, &out.SubmittedAt, &out.PublishedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Comment", out.ID), out)
	}
	return out, nil
}

func (c *CommentClient) BulkCreate(ctx context.Context, inputs []*Comment) ([]*Comment, error) {
	if len(inputs) == 0 {
		return []*Comment{}, nil
	}
	rowsSpec := make([][]any, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		now := time.Now().UTC()
		if input.ID == "" {
			v, err := id.NewV7()
			if err != nil {
				return nil, err
			}
			input.ID = v
		}
		if input.SubmittedAt.IsZero() {
			input.SubmittedAt = now
		}
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Comment", validation.OpCreate, commentValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := []any{input.ID, input.PostID, input.AuthorID, input.ParentID, input.AuthorName, input.AuthorEmail, input.AuthorURL, input.Content, input.Status, input.SubmittedAt, input.PublishedAt, input.UpdatedAt}
		rowsSpec = append(rowsSpec, row)
	}
	spec := runtime.BulkInsertSpec{
		Table:     "comments",
		Columns:   []string{"id", "post_id", "author_id", "parent_id", "author_name", "author_email", "author_url", "content", "status", "submitted_at", "published_at", "updated_at"},
		Returning: []string{"id", "post_id", "author_id", "parent_id", "author_name", "author_email", "author_url", "content", "status", "submitted_at", "published_at", "updated_at"},
		Rows:      rowsSpec,
	}
	sql, args, err := runtime.BuildBulkInsertSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var created []*Comment
	for rows.Next() {
		item := new(Comment)
		if err := rows.Scan(&item.ID, &item.PostID, &item.AuthorID, &item.ParentID, &item.AuthorName, &item.AuthorEmail, &item.AuthorURL, &item.Content, &item.Status, &item.SubmittedAt, &item.PublishedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		created = append(created, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Comment", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return created, nil
}

func (c *CommentClient) ByID(ctx context.Context, id string) (*Comment, error) {
	var cachedKey string
	if c.cache != nil {
		cachedKey = makeCacheKey("Comment", id)
		if value, ok, err := c.cache.Get(ctx, cachedKey); err != nil {
			return nil, err
		} else if ok {
			if entity, ok := value.(*Comment); ok {
				return entity, nil
			}
		}
	}
	row := c.db.Pool.QueryRow(ctx, commentSelectQuery, id)
	out := new(Comment)
	if err := row.Scan(&out.ID, &out.PostID, &out.AuthorID, &out.ParentID, &out.AuthorName, &out.AuthorEmail, &out.AuthorURL, &out.Content, &out.Status, &out.SubmittedAt, &out.PublishedAt, &out.UpdatedAt); err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, nil
		}
		return nil, err
	}
	if c.cache != nil {
		cachedKey = makeCacheKey("Comment", out.ID)
		_ = c.cache.Set(ctx, cachedKey, out)
	}
	return out, nil
}

func (c *CommentClient) List(ctx context.Context, limit, offset int) ([]*Comment, error) {
	if limit <= 0 {
		limit = 20
	}
	if offset < 0 {
		offset = 0
	}
	rows, err := c.db.Pool.Query(ctx, commentListQuery, limit, offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Comment
	for rows.Next() {
		item := new(Comment)
		if err := rows.Scan(&item.ID, &item.PostID, &item.AuthorID, &item.ParentID, &item.AuthorName, &item.AuthorEmail, &item.AuthorURL, &item.Content, &item.Status, &item.SubmittedAt, &item.PublishedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (c *CommentClient) Count(ctx context.Context) (int, error) {
	row := c.db.Pool.QueryRow(ctx, commentCountQuery)
	var total int
	if err := row.Scan(&total); err != nil {
		return 0, err
	}
	return total, nil
}

func (c *CommentClient) Update(ctx context.Context, input *Comment) (*Comment, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	if input.ID == "" {
		return nil, errors.New("id is required")
	}
	now := time.Now().UTC()
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Comment", validation.OpUpdate, commentValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, commentUpdateQuery, input.PostID, input.AuthorID, input.ParentID, input.AuthorName, input.AuthorEmail, input.AuthorURL, input.Content, input.Status, input.PublishedAt, input.UpdatedAt, input.ID)
	out := new(Comment)
	if err := row.Scan(&out.ID, &out.PostID, &out.AuthorID, &out.ParentID, &out.AuthorName, &out.AuthorEmail, &out.AuthorURL, &out.Content, &out.Status, &out.SubmittedAt, &out.PublishedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Comment", out.ID), out)
	}
	return out, nil
}

func (c *CommentClient) BulkUpdate(ctx context.Context, inputs []*Comment) ([]*Comment, error) {
	if len(inputs) == 0 {
		return []*Comment{}, nil
	}
	specs := make([]runtime.BulkUpdateRow, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		if input.ID == "" {
			return nil, errors.New("id is required")
		}
		now := time.Now().UTC()
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Comment", validation.OpUpdate, commentValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := runtime.BulkUpdateRow{
			Primary: input.ID,
			Values:  []any{input.PostID, input.AuthorID, input.ParentID, input.AuthorName, input.AuthorEmail, input.AuthorURL, input.Content, input.Status, input.PublishedAt, input.UpdatedAt},
		}
		specs = append(specs, row)
	}
	spec := runtime.BulkUpdateSpec{
		Table:         "comments",
		PrimaryColumn: "id",
		Columns:       []string{"post_id", "author_id", "parent_id", "author_name", "author_email", "author_url", "content", "status", "published_at", "updated_at"},
		Returning:     []string{"id", "post_id", "author_id", "parent_id", "author_name", "author_email", "author_url", "content", "status", "submitted_at", "published_at", "updated_at"},
		Rows:          specs,
	}
	sql, args, err := runtime.BuildBulkUpdateSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var updated []*Comment
	for rows.Next() {
		item := new(Comment)
		if err := rows.Scan(&item.ID, &item.PostID, &item.AuthorID, &item.ParentID, &item.AuthorName, &item.AuthorEmail, &item.AuthorURL, &item.Content, &item.Status, &item.SubmittedAt, &item.PublishedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		updated = append(updated, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Comment", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return updated, nil
}

func (c *CommentClient) Delete(ctx context.Context, id string) error {
	if _, err := c.db.Pool.Exec(ctx, commentDeleteQuery, id); err != nil {
		return err
	}
	if c.cache != nil {
		_ = c.cache.Delete(ctx, makeCacheKey("Comment", id))
	}
	return nil
}

func (c *CommentClient) BulkDelete(ctx context.Context, ids []string) (int64, error) {
	if len(ids) == 0 {
		return 0, nil
	}
	spec := runtime.BulkDeleteSpec{
		Table:         "comments",
		PrimaryColumn: "id",
		IDs:           make([]any, len(ids)),
	}
	for i, id := range ids {
		spec.IDs[i] = id
	}
	sql, args, err := runtime.BuildBulkDeleteSQL(spec)
	if err != nil {
		return 0, err
	}
	tag, err := c.db.Pool.Exec(ctx, sql, args...)
	if err != nil {
		return 0, err
	}
	if c.cache != nil {
		for _, id := range ids {
			_ = c.cache.Delete(ctx, makeCacheKey("Comment", id))
		}
	}
	return int64(tag.RowsAffected()), nil
}

type CommentQuery struct {
	db           *pg.DB
	predicates   []runtime.Predicate
	orders       []runtime.Order
	limit        *int
	offset       int
	defaultLimit int
	maxLimit     int
}

func (c *CommentClient) Query() *CommentQuery {
	return &CommentQuery{db: c.db, defaultLimit: 50, maxLimit: 500}
}

func (q *CommentQuery) Limit(n int) *CommentQuery {
	if n <= 0 {
		q.limit = nil
		return q
	}
	q.limit = &n
	return q
}

func (q *CommentQuery) Offset(n int) *CommentQuery {
	if n < 0 {
		return q
	}
	q.offset = n
	return q
}

func (q *CommentQuery) WherePostIDEq(value string) *CommentQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "post_id", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *CommentQuery) WhereAuthorIDEq(value string) *CommentQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "author_id", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *CommentQuery) WhereStatusEq(value string) *CommentQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "status", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *CommentQuery) OrderBySubmittedAtAsc() *CommentQuery {
	q.orders = append(q.orders, runtime.Order{Column: "submitted_at", Direction: runtime.SortAsc})
	return q
}

func (q *CommentQuery) All(ctx context.Context) ([]*Comment, error) {
	spec := runtime.SelectSpec{
		Table:      "comments",
		Columns:    []string{"id", "post_id", "author_id", "parent_id", "author_name", "author_email", "author_url", "content", "status", "submitted_at", "published_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Comment
	for rows.Next() {
		item := new(Comment)
		if err := rows.Scan(&item.ID, &item.PostID, &item.AuthorID, &item.ParentID, &item.AuthorName, &item.AuthorEmail, &item.AuthorURL, &item.Content, &item.Status, &item.SubmittedAt, &item.PublishedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (q *CommentQuery) Stream(ctx context.Context) (*runtime.Stream[*Comment], error) {
	spec := runtime.SelectSpec{
		Table:      "comments",
		Columns:    []string{"id", "post_id", "author_id", "parent_id", "author_name", "author_email", "author_url", "content", "status", "submitted_at", "published_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	stream := runtime.NewStream[*Comment](rows, func(rows pgx.Rows) (*Comment, error) {
		item := new(Comment)
		if err := rows.Scan(&item.ID, &item.PostID, &item.AuthorID, &item.ParentID, &item.AuthorName, &item.AuthorEmail, &item.AuthorURL, &item.Content, &item.Status, &item.SubmittedAt, &item.PublishedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		return item, nil
	})
	return stream, nil
}

func (q *CommentQuery) First(ctx context.Context) (*Comment, error) {
	clone := q.clone()
	one := 1
	clone.limit = &one
	items, err := clone.All(ctx)
	if err != nil {
		return nil, err
	}
	if len(items) == 0 {
		return nil, nil
	}
	return items[0], nil
}

func (q *CommentQuery) Count(ctx context.Context) (int, error) {
	spec := runtime.AggregateSpec{
		Table:      "comments",
		Predicates: q.predicates,
		Aggregate:  runtime.Aggregate{Func: runtime.AggCount, Column: "*"},
	}
	row := q.db.Aggregate(ctx, spec)
	var out int
	if err := row.Scan(&out); err != nil {
		return out, err
	}
	return out, nil
}

func (q *CommentQuery) clone() *CommentQuery {
	cp := *q
	if len(q.predicates) > 0 {
		cp.predicates = append([]runtime.Predicate(nil), q.predicates...)
	}
	if len(q.orders) > 0 {
		cp.orders = append([]runtime.Order(nil), q.orders...)
	}
	if q.limit != nil {
		limit := *q.limit
		cp.limit = &limit
	}
	return &cp
}

func (q *CommentQuery) effectiveLimit() int {
	if q.limit != nil {
		limit := *q.limit
		if q.maxLimit > 0 && limit > q.maxLimit {
			return q.maxLimit
		}
		return limit
	}
	limit := q.defaultLimit
	if limit <= 0 && q.maxLimit > 0 {
		return q.maxLimit
	}
	if q.maxLimit > 0 && limit > q.maxLimit {
		return q.maxLimit
	}
	return limit
}

const commentPostRelationQuery = `SELECT id, author_id, featured_media_id, title, slug, status, type, excerpt, content, seo, published_at, created_at, updated_at FROM posts WHERE id IN (%s)`

func (c *CommentClient) LoadPost(ctx context.Context, parents ...*Comment) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureCommentEdges(parent)
		edges.markLoaded("post")
		var fk keyType
		fk = parent.PostID
		if isZero(fk) {
			edges.Post = nil
			continue
		}
		if _, ok := seen[fk]; !ok {
			seen[fk] = struct{}{}
			keys = append(keys, fk)
		}
	}
	if len(keys) == 0 {
		return nil
	}
	sql, args := buildInQuery(commentPostRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	related := make(map[keyType]*Post, len(keys))
	for rows.Next() {
		item := new(Post)
		if err := rows.Scan(&item.ID, &item.AuthorID, &item.FeaturedMediaID, &item.Title, &item.Slug, &item.Status, &item.Type, &item.Excerpt, &item.Content, &item.Seo, &item.PublishedAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return err
		}
		key := item.ID
		related[key] = item
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureCommentEdges(parent)
		var fk keyType
		fk = parent.PostID
		if isZero(fk) {
			edges.Post = nil
			continue
		}
		if item, ok := related[fk]; ok {
			edges.Post = item
		} else {
			edges.Post = nil
		}
	}
	return nil
}

const commentAuthorRelationQuery = `SELECT id, username, email, password_hash, display_name, bio, avatar_url, website_url, last_login_at, created_at, updated_at FROM users WHERE id IN (%s)`

func (c *CommentClient) LoadAuthor(ctx context.Context, parents ...*Comment) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureCommentEdges(parent)
		edges.markLoaded("author")
		var fk keyType
		fkPtr := parent.AuthorID
		if fkPtr == nil {
			edges.Author = nil
			continue
		}
		fk = *fkPtr
		if isZero(fk) {
			edges.Author = nil
			continue
		}
		if _, ok := seen[fk]; !ok {
			seen[fk] = struct{}{}
			keys = append(keys, fk)
		}
	}
	if len(keys) == 0 {
		return nil
	}
	sql, args := buildInQuery(commentAuthorRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	related := make(map[keyType]*User, len(keys))
	for rows.Next() {
		item := new(User)
		if err := rows.Scan(&item.ID, &item.Username, &item.Email, &item.PasswordHash, &item.DisplayName, &item.Bio, &item.AvatarURL, &item.WebsiteURL, &item.LastLoginAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return err
		}
		key := item.ID
		related[key] = item
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureCommentEdges(parent)
		var fk keyType
		fkPtr := parent.AuthorID
		if fkPtr == nil {
			edges.Author = nil
			continue
		}
		fk = *fkPtr
		if isZero(fk) {
			edges.Author = nil
			continue
		}
		if item, ok := related[fk]; ok {
			edges.Author = item
		} else {
			edges.Author = nil
		}
	}
	return nil
}

const commentParentRelationQuery = `SELECT id, post_id, author_id, parent_id, author_name, author_email, author_url, content, status, submitted_at, published_at, updated_at FROM comments WHERE id IN (%s)`

func (c *CommentClient) LoadParent(ctx context.Context, parents ...*Comment) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureCommentEdges(parent)
		edges.markLoaded("parent")
		var fk keyType
		fkPtr := parent.ParentID
		if fkPtr == nil {
			edges.Parent = nil
			continue
		}
		fk = *fkPtr
		if isZero(fk) {
			edges.Parent = nil
			continue
		}
		if _, ok := seen[fk]; !ok {
			seen[fk] = struct{}{}
			keys = append(keys, fk)
		}
	}
	if len(keys) == 0 {
		return nil
	}
	sql, args := buildInQuery(commentParentRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	related := make(map[keyType]*Comment, len(keys))
	for rows.Next() {
		item := new(Comment)
		if err := rows.Scan(&item.ID, &item.PostID, &item.AuthorID, &item.ParentID, &item.AuthorName, &item.AuthorEmail, &item.AuthorURL, &item.Content, &item.Status, &item.SubmittedAt, &item.PublishedAt, &item.UpdatedAt); err != nil {
			return err
		}
		key := item.ID
		related[key] = item
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureCommentEdges(parent)
		var fk keyType
		fkPtr := parent.ParentID
		if fkPtr == nil {
			edges.Parent = nil
			continue
		}
		fk = *fkPtr
		if isZero(fk) {
			edges.Parent = nil
			continue
		}
		if item, ok := related[fk]; ok {
			edges.Parent = item
		} else {
			edges.Parent = nil
		}
	}
	return nil
}

const mediaInsertQuery = `INSERT INTO medias (id, uploaded_by_id, file_name, mime_type, storage_key, url, title, alt_text, caption, description, file_size_bytes, metadata, created_at, updated_at) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14) RETURNING id, uploaded_by_id, file_name, mime_type, storage_key, url, title, alt_text, caption, description, file_size_bytes, metadata, created_at, updated_at`
const mediaSelectQuery = `SELECT id, uploaded_by_id, file_name, mime_type, storage_key, url, title, alt_text, caption, description, file_size_bytes, metadata, created_at, updated_at FROM medias WHERE id = $1`
const mediaListQuery = `SELECT id, uploaded_by_id, file_name, mime_type, storage_key, url, title, alt_text, caption, description, file_size_bytes, metadata, created_at, updated_at FROM medias ORDER BY id LIMIT $1 OFFSET $2`
const mediaUpdateQuery = `UPDATE medias SET uploaded_by_id = $1, file_name = $2, mime_type = $3, storage_key = $4, url = $5, title = $6, alt_text = $7, caption = $8, description = $9, file_size_bytes = $10, metadata = $11, updated_at = $12 WHERE id = $13 RETURNING id, uploaded_by_id, file_name, mime_type, storage_key, url, title, alt_text, caption, description, file_size_bytes, metadata, created_at, updated_at`
const mediaCountQuery = `SELECT COUNT(*) FROM medias`
const mediaDeleteQuery = `DELETE FROM medias WHERE id = $1`

type MediaClient struct {
	db    *pg.DB
	cache cache.Store
}

func (c *MediaClient) Create(ctx context.Context, input *Media) (*Media, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	now := time.Now().UTC()
	if input.ID == "" {
		v, err := id.NewV7()
		if err != nil {
			return nil, err
		}
		input.ID = v
	}
	if input.CreatedAt.IsZero() {
		input.CreatedAt = now
	}
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Media", validation.OpCreate, mediaValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, mediaInsertQuery, input.ID, input.UploadedByID, input.FileName, input.MimeType, input.StorageKey, input.URL, input.Title, input.AltText, input.Caption, input.Description, input.FileSizeBytes, input.Metadata, input.CreatedAt, input.UpdatedAt)
	out := new(Media)
	if err := row.Scan(&out.ID, &out.UploadedByID, &out.FileName, &out.MimeType, &out.StorageKey, &out.URL, &out.Title, &out.AltText, &out.Caption, &out.Description, &out.FileSizeBytes, &out.Metadata, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Media", out.ID), out)
	}
	return out, nil
}

func (c *MediaClient) BulkCreate(ctx context.Context, inputs []*Media) ([]*Media, error) {
	if len(inputs) == 0 {
		return []*Media{}, nil
	}
	rowsSpec := make([][]any, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		now := time.Now().UTC()
		if input.ID == "" {
			v, err := id.NewV7()
			if err != nil {
				return nil, err
			}
			input.ID = v
		}
		if input.CreatedAt.IsZero() {
			input.CreatedAt = now
		}
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Media", validation.OpCreate, mediaValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := []any{input.ID, input.UploadedByID, input.FileName, input.MimeType, input.StorageKey, input.URL, input.Title, input.AltText, input.Caption, input.Description, input.FileSizeBytes, input.Metadata, input.CreatedAt, input.UpdatedAt}
		rowsSpec = append(rowsSpec, row)
	}
	spec := runtime.BulkInsertSpec{
		Table:     "medias",
		Columns:   []string{"id", "uploaded_by_id", "file_name", "mime_type", "storage_key", "url", "title", "alt_text", "caption", "description", "file_size_bytes", "metadata", "created_at", "updated_at"},
		Returning: []string{"id", "uploaded_by_id", "file_name", "mime_type", "storage_key", "url", "title", "alt_text", "caption", "description", "file_size_bytes", "metadata", "created_at", "updated_at"},
		Rows:      rowsSpec,
	}
	sql, args, err := runtime.BuildBulkInsertSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var created []*Media
	for rows.Next() {
		item := new(Media)
		if err := rows.Scan(&item.ID, &item.UploadedByID, &item.FileName, &item.MimeType, &item.StorageKey, &item.URL, &item.Title, &item.AltText, &item.Caption, &item.Description, &item.FileSizeBytes, &item.Metadata, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		created = append(created, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Media", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return created, nil
}

func (c *MediaClient) ByID(ctx context.Context, id string) (*Media, error) {
	var cachedKey string
	if c.cache != nil {
		cachedKey = makeCacheKey("Media", id)
		if value, ok, err := c.cache.Get(ctx, cachedKey); err != nil {
			return nil, err
		} else if ok {
			if entity, ok := value.(*Media); ok {
				return entity, nil
			}
		}
	}
	row := c.db.Pool.QueryRow(ctx, mediaSelectQuery, id)
	out := new(Media)
	if err := row.Scan(&out.ID, &out.UploadedByID, &out.FileName, &out.MimeType, &out.StorageKey, &out.URL, &out.Title, &out.AltText, &out.Caption, &out.Description, &out.FileSizeBytes, &out.Metadata, &out.CreatedAt, &out.UpdatedAt); err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, nil
		}
		return nil, err
	}
	if c.cache != nil {
		cachedKey = makeCacheKey("Media", out.ID)
		_ = c.cache.Set(ctx, cachedKey, out)
	}
	return out, nil
}

func (c *MediaClient) List(ctx context.Context, limit, offset int) ([]*Media, error) {
	if limit <= 0 {
		limit = 20
	}
	if offset < 0 {
		offset = 0
	}
	rows, err := c.db.Pool.Query(ctx, mediaListQuery, limit, offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Media
	for rows.Next() {
		item := new(Media)
		if err := rows.Scan(&item.ID, &item.UploadedByID, &item.FileName, &item.MimeType, &item.StorageKey, &item.URL, &item.Title, &item.AltText, &item.Caption, &item.Description, &item.FileSizeBytes, &item.Metadata, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (c *MediaClient) Count(ctx context.Context) (int, error) {
	row := c.db.Pool.QueryRow(ctx, mediaCountQuery)
	var total int
	if err := row.Scan(&total); err != nil {
		return 0, err
	}
	return total, nil
}

func (c *MediaClient) Update(ctx context.Context, input *Media) (*Media, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	if input.ID == "" {
		return nil, errors.New("id is required")
	}
	now := time.Now().UTC()
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Media", validation.OpUpdate, mediaValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, mediaUpdateQuery, input.UploadedByID, input.FileName, input.MimeType, input.StorageKey, input.URL, input.Title, input.AltText, input.Caption, input.Description, input.FileSizeBytes, input.Metadata, input.UpdatedAt, input.ID)
	out := new(Media)
	if err := row.Scan(&out.ID, &out.UploadedByID, &out.FileName, &out.MimeType, &out.StorageKey, &out.URL, &out.Title, &out.AltText, &out.Caption, &out.Description, &out.FileSizeBytes, &out.Metadata, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Media", out.ID), out)
	}
	return out, nil
}

func (c *MediaClient) BulkUpdate(ctx context.Context, inputs []*Media) ([]*Media, error) {
	if len(inputs) == 0 {
		return []*Media{}, nil
	}
	specs := make([]runtime.BulkUpdateRow, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		if input.ID == "" {
			return nil, errors.New("id is required")
		}
		now := time.Now().UTC()
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Media", validation.OpUpdate, mediaValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := runtime.BulkUpdateRow{
			Primary: input.ID,
			Values:  []any{input.UploadedByID, input.FileName, input.MimeType, input.StorageKey, input.URL, input.Title, input.AltText, input.Caption, input.Description, input.FileSizeBytes, input.Metadata, input.UpdatedAt},
		}
		specs = append(specs, row)
	}
	spec := runtime.BulkUpdateSpec{
		Table:         "medias",
		PrimaryColumn: "id",
		Columns:       []string{"uploaded_by_id", "file_name", "mime_type", "storage_key", "url", "title", "alt_text", "caption", "description", "file_size_bytes", "metadata", "updated_at"},
		Returning:     []string{"id", "uploaded_by_id", "file_name", "mime_type", "storage_key", "url", "title", "alt_text", "caption", "description", "file_size_bytes", "metadata", "created_at", "updated_at"},
		Rows:          specs,
	}
	sql, args, err := runtime.BuildBulkUpdateSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var updated []*Media
	for rows.Next() {
		item := new(Media)
		if err := rows.Scan(&item.ID, &item.UploadedByID, &item.FileName, &item.MimeType, &item.StorageKey, &item.URL, &item.Title, &item.AltText, &item.Caption, &item.Description, &item.FileSizeBytes, &item.Metadata, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		updated = append(updated, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Media", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return updated, nil
}

func (c *MediaClient) Delete(ctx context.Context, id string) error {
	if _, err := c.db.Pool.Exec(ctx, mediaDeleteQuery, id); err != nil {
		return err
	}
	if c.cache != nil {
		_ = c.cache.Delete(ctx, makeCacheKey("Media", id))
	}
	return nil
}

func (c *MediaClient) BulkDelete(ctx context.Context, ids []string) (int64, error) {
	if len(ids) == 0 {
		return 0, nil
	}
	spec := runtime.BulkDeleteSpec{
		Table:         "medias",
		PrimaryColumn: "id",
		IDs:           make([]any, len(ids)),
	}
	for i, id := range ids {
		spec.IDs[i] = id
	}
	sql, args, err := runtime.BuildBulkDeleteSQL(spec)
	if err != nil {
		return 0, err
	}
	tag, err := c.db.Pool.Exec(ctx, sql, args...)
	if err != nil {
		return 0, err
	}
	if c.cache != nil {
		for _, id := range ids {
			_ = c.cache.Delete(ctx, makeCacheKey("Media", id))
		}
	}
	return int64(tag.RowsAffected()), nil
}

type MediaQuery struct {
	db           *pg.DB
	predicates   []runtime.Predicate
	orders       []runtime.Order
	limit        *int
	offset       int
	defaultLimit int
	maxLimit     int
}

func (c *MediaClient) Query() *MediaQuery {
	return &MediaQuery{db: c.db, defaultLimit: 50, maxLimit: 200}
}

func (q *MediaQuery) Limit(n int) *MediaQuery {
	if n <= 0 {
		q.limit = nil
		return q
	}
	q.limit = &n
	return q
}

func (q *MediaQuery) Offset(n int) *MediaQuery {
	if n < 0 {
		return q
	}
	q.offset = n
	return q
}

func (q *MediaQuery) WhereIDEq(value string) *MediaQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "id", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *MediaQuery) WhereUploadedByIDEq(value string) *MediaQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "uploaded_by_id", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *MediaQuery) WhereMimeTypeILike(value string) *MediaQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "mime_type", Operator: runtime.OpILike, Value: value})
	return q
}

func (q *MediaQuery) OrderByCreatedAtDesc() *MediaQuery {
	q.orders = append(q.orders, runtime.Order{Column: "created_at", Direction: runtime.SortDesc})
	return q
}

func (q *MediaQuery) All(ctx context.Context) ([]*Media, error) {
	spec := runtime.SelectSpec{
		Table:      "medias",
		Columns:    []string{"id", "uploaded_by_id", "file_name", "mime_type", "storage_key", "url", "title", "alt_text", "caption", "description", "file_size_bytes", "metadata", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Media
	for rows.Next() {
		item := new(Media)
		if err := rows.Scan(&item.ID, &item.UploadedByID, &item.FileName, &item.MimeType, &item.StorageKey, &item.URL, &item.Title, &item.AltText, &item.Caption, &item.Description, &item.FileSizeBytes, &item.Metadata, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (q *MediaQuery) Stream(ctx context.Context) (*runtime.Stream[*Media], error) {
	spec := runtime.SelectSpec{
		Table:      "medias",
		Columns:    []string{"id", "uploaded_by_id", "file_name", "mime_type", "storage_key", "url", "title", "alt_text", "caption", "description", "file_size_bytes", "metadata", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	stream := runtime.NewStream[*Media](rows, func(rows pgx.Rows) (*Media, error) {
		item := new(Media)
		if err := rows.Scan(&item.ID, &item.UploadedByID, &item.FileName, &item.MimeType, &item.StorageKey, &item.URL, &item.Title, &item.AltText, &item.Caption, &item.Description, &item.FileSizeBytes, &item.Metadata, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		return item, nil
	})
	return stream, nil
}

func (q *MediaQuery) First(ctx context.Context) (*Media, error) {
	clone := q.clone()
	one := 1
	clone.limit = &one
	items, err := clone.All(ctx)
	if err != nil {
		return nil, err
	}
	if len(items) == 0 {
		return nil, nil
	}
	return items[0], nil
}

func (q *MediaQuery) Count(ctx context.Context) (int, error) {
	spec := runtime.AggregateSpec{
		Table:      "medias",
		Predicates: q.predicates,
		Aggregate:  runtime.Aggregate{Func: runtime.AggCount, Column: "*"},
	}
	row := q.db.Aggregate(ctx, spec)
	var out int
	if err := row.Scan(&out); err != nil {
		return out, err
	}
	return out, nil
}

func (q *MediaQuery) clone() *MediaQuery {
	cp := *q
	if len(q.predicates) > 0 {
		cp.predicates = append([]runtime.Predicate(nil), q.predicates...)
	}
	if len(q.orders) > 0 {
		cp.orders = append([]runtime.Order(nil), q.orders...)
	}
	if q.limit != nil {
		limit := *q.limit
		cp.limit = &limit
	}
	return &cp
}

func (q *MediaQuery) effectiveLimit() int {
	if q.limit != nil {
		limit := *q.limit
		if q.maxLimit > 0 && limit > q.maxLimit {
			return q.maxLimit
		}
		return limit
	}
	limit := q.defaultLimit
	if limit <= 0 && q.maxLimit > 0 {
		return q.maxLimit
	}
	if q.maxLimit > 0 && limit > q.maxLimit {
		return q.maxLimit
	}
	return limit
}

const mediaUploadedByRelationQuery = `SELECT id, username, email, password_hash, display_name, bio, avatar_url, website_url, last_login_at, created_at, updated_at FROM users WHERE id IN (%s)`

func (c *MediaClient) LoadUploadedBy(ctx context.Context, parents ...*Media) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureMediaEdges(parent)
		edges.markLoaded("uploaded_by")
		var fk keyType
		fkPtr := parent.UploadedByID
		if fkPtr == nil {
			edges.UploadedBy = nil
			continue
		}
		fk = *fkPtr
		if isZero(fk) {
			edges.UploadedBy = nil
			continue
		}
		if _, ok := seen[fk]; !ok {
			seen[fk] = struct{}{}
			keys = append(keys, fk)
		}
	}
	if len(keys) == 0 {
		return nil
	}
	sql, args := buildInQuery(mediaUploadedByRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	related := make(map[keyType]*User, len(keys))
	for rows.Next() {
		item := new(User)
		if err := rows.Scan(&item.ID, &item.Username, &item.Email, &item.PasswordHash, &item.DisplayName, &item.Bio, &item.AvatarURL, &item.WebsiteURL, &item.LastLoginAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return err
		}
		key := item.ID
		related[key] = item
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureMediaEdges(parent)
		var fk keyType
		fkPtr := parent.UploadedByID
		if fkPtr == nil {
			edges.UploadedBy = nil
			continue
		}
		fk = *fkPtr
		if isZero(fk) {
			edges.UploadedBy = nil
			continue
		}
		if item, ok := related[fk]; ok {
			edges.UploadedBy = item
		} else {
			edges.UploadedBy = nil
		}
	}
	return nil
}

const optionInsertQuery = `INSERT INTO options (id, name, value, autoload, created_at, updated_at) VALUES ($1, $2, $3, $4, $5, $6) RETURNING id, name, value, autoload, created_at, updated_at`
const optionSelectQuery = `SELECT id, name, value, autoload, created_at, updated_at FROM options WHERE id = $1`
const optionListQuery = `SELECT id, name, value, autoload, created_at, updated_at FROM options ORDER BY id LIMIT $1 OFFSET $2`
const optionUpdateQuery = `UPDATE options SET name = $1, value = $2, autoload = $3, updated_at = $4 WHERE id = $5 RETURNING id, name, value, autoload, created_at, updated_at`
const optionCountQuery = `SELECT COUNT(*) FROM options`
const optionDeleteQuery = `DELETE FROM options WHERE id = $1`

type OptionClient struct {
	db    *pg.DB
	cache cache.Store
}

func (c *OptionClient) Create(ctx context.Context, input *Option) (*Option, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	now := time.Now().UTC()
	if input.ID == "" {
		v, err := id.NewV7()
		if err != nil {
			return nil, err
		}
		input.ID = v
	}
	if input.CreatedAt.IsZero() {
		input.CreatedAt = now
	}
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Option", validation.OpCreate, optionValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, optionInsertQuery, input.ID, input.Name, input.Value, input.Autoload, input.CreatedAt, input.UpdatedAt)
	out := new(Option)
	if err := row.Scan(&out.ID, &out.Name, &out.Value, &out.Autoload, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Option", out.ID), out)
	}
	return out, nil
}

func (c *OptionClient) BulkCreate(ctx context.Context, inputs []*Option) ([]*Option, error) {
	if len(inputs) == 0 {
		return []*Option{}, nil
	}
	rowsSpec := make([][]any, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		now := time.Now().UTC()
		if input.ID == "" {
			v, err := id.NewV7()
			if err != nil {
				return nil, err
			}
			input.ID = v
		}
		if input.CreatedAt.IsZero() {
			input.CreatedAt = now
		}
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Option", validation.OpCreate, optionValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := []any{input.ID, input.Name, input.Value, input.Autoload, input.CreatedAt, input.UpdatedAt}
		rowsSpec = append(rowsSpec, row)
	}
	spec := runtime.BulkInsertSpec{
		Table:     "options",
		Columns:   []string{"id", "name", "value", "autoload", "created_at", "updated_at"},
		Returning: []string{"id", "name", "value", "autoload", "created_at", "updated_at"},
		Rows:      rowsSpec,
	}
	sql, args, err := runtime.BuildBulkInsertSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var created []*Option
	for rows.Next() {
		item := new(Option)
		if err := rows.Scan(&item.ID, &item.Name, &item.Value, &item.Autoload, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		created = append(created, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Option", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return created, nil
}

func (c *OptionClient) ByID(ctx context.Context, id string) (*Option, error) {
	var cachedKey string
	if c.cache != nil {
		cachedKey = makeCacheKey("Option", id)
		if value, ok, err := c.cache.Get(ctx, cachedKey); err != nil {
			return nil, err
		} else if ok {
			if entity, ok := value.(*Option); ok {
				return entity, nil
			}
		}
	}
	row := c.db.Pool.QueryRow(ctx, optionSelectQuery, id)
	out := new(Option)
	if err := row.Scan(&out.ID, &out.Name, &out.Value, &out.Autoload, &out.CreatedAt, &out.UpdatedAt); err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, nil
		}
		return nil, err
	}
	if c.cache != nil {
		cachedKey = makeCacheKey("Option", out.ID)
		_ = c.cache.Set(ctx, cachedKey, out)
	}
	return out, nil
}

func (c *OptionClient) List(ctx context.Context, limit, offset int) ([]*Option, error) {
	if limit <= 0 {
		limit = 20
	}
	if offset < 0 {
		offset = 0
	}
	rows, err := c.db.Pool.Query(ctx, optionListQuery, limit, offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Option
	for rows.Next() {
		item := new(Option)
		if err := rows.Scan(&item.ID, &item.Name, &item.Value, &item.Autoload, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (c *OptionClient) Count(ctx context.Context) (int, error) {
	row := c.db.Pool.QueryRow(ctx, optionCountQuery)
	var total int
	if err := row.Scan(&total); err != nil {
		return 0, err
	}
	return total, nil
}

func (c *OptionClient) Update(ctx context.Context, input *Option) (*Option, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	if input.ID == "" {
		return nil, errors.New("id is required")
	}
	now := time.Now().UTC()
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Option", validation.OpUpdate, optionValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, optionUpdateQuery, input.Name, input.Value, input.Autoload, input.UpdatedAt, input.ID)
	out := new(Option)
	if err := row.Scan(&out.ID, &out.Name, &out.Value, &out.Autoload, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Option", out.ID), out)
	}
	return out, nil
}

func (c *OptionClient) BulkUpdate(ctx context.Context, inputs []*Option) ([]*Option, error) {
	if len(inputs) == 0 {
		return []*Option{}, nil
	}
	specs := make([]runtime.BulkUpdateRow, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		if input.ID == "" {
			return nil, errors.New("id is required")
		}
		now := time.Now().UTC()
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Option", validation.OpUpdate, optionValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := runtime.BulkUpdateRow{
			Primary: input.ID,
			Values:  []any{input.Name, input.Value, input.Autoload, input.UpdatedAt},
		}
		specs = append(specs, row)
	}
	spec := runtime.BulkUpdateSpec{
		Table:         "options",
		PrimaryColumn: "id",
		Columns:       []string{"name", "value", "autoload", "updated_at"},
		Returning:     []string{"id", "name", "value", "autoload", "created_at", "updated_at"},
		Rows:          specs,
	}
	sql, args, err := runtime.BuildBulkUpdateSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var updated []*Option
	for rows.Next() {
		item := new(Option)
		if err := rows.Scan(&item.ID, &item.Name, &item.Value, &item.Autoload, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		updated = append(updated, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Option", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return updated, nil
}

func (c *OptionClient) Delete(ctx context.Context, id string) error {
	if _, err := c.db.Pool.Exec(ctx, optionDeleteQuery, id); err != nil {
		return err
	}
	if c.cache != nil {
		_ = c.cache.Delete(ctx, makeCacheKey("Option", id))
	}
	return nil
}

func (c *OptionClient) BulkDelete(ctx context.Context, ids []string) (int64, error) {
	if len(ids) == 0 {
		return 0, nil
	}
	spec := runtime.BulkDeleteSpec{
		Table:         "options",
		PrimaryColumn: "id",
		IDs:           make([]any, len(ids)),
	}
	for i, id := range ids {
		spec.IDs[i] = id
	}
	sql, args, err := runtime.BuildBulkDeleteSQL(spec)
	if err != nil {
		return 0, err
	}
	tag, err := c.db.Pool.Exec(ctx, sql, args...)
	if err != nil {
		return 0, err
	}
	if c.cache != nil {
		for _, id := range ids {
			_ = c.cache.Delete(ctx, makeCacheKey("Option", id))
		}
	}
	return int64(tag.RowsAffected()), nil
}

type OptionQuery struct {
	db           *pg.DB
	predicates   []runtime.Predicate
	orders       []runtime.Order
	limit        *int
	offset       int
	defaultLimit int
	maxLimit     int
}

func (c *OptionClient) Query() *OptionQuery {
	return &OptionQuery{db: c.db, defaultLimit: 100, maxLimit: 500}
}

func (q *OptionQuery) Limit(n int) *OptionQuery {
	if n <= 0 {
		q.limit = nil
		return q
	}
	q.limit = &n
	return q
}

func (q *OptionQuery) Offset(n int) *OptionQuery {
	if n < 0 {
		return q
	}
	q.offset = n
	return q
}

func (q *OptionQuery) WhereNameEq(value string) *OptionQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "name", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *OptionQuery) OrderByIDAsc() *OptionQuery {
	q.orders = append(q.orders, runtime.Order{Column: "id", Direction: runtime.SortAsc})
	return q
}

func (q *OptionQuery) All(ctx context.Context) ([]*Option, error) {
	spec := runtime.SelectSpec{
		Table:      "options",
		Columns:    []string{"id", "name", "value", "autoload", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Option
	for rows.Next() {
		item := new(Option)
		if err := rows.Scan(&item.ID, &item.Name, &item.Value, &item.Autoload, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (q *OptionQuery) Stream(ctx context.Context) (*runtime.Stream[*Option], error) {
	spec := runtime.SelectSpec{
		Table:      "options",
		Columns:    []string{"id", "name", "value", "autoload", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	stream := runtime.NewStream[*Option](rows, func(rows pgx.Rows) (*Option, error) {
		item := new(Option)
		if err := rows.Scan(&item.ID, &item.Name, &item.Value, &item.Autoload, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		return item, nil
	})
	return stream, nil
}

func (q *OptionQuery) First(ctx context.Context) (*Option, error) {
	clone := q.clone()
	one := 1
	clone.limit = &one
	items, err := clone.All(ctx)
	if err != nil {
		return nil, err
	}
	if len(items) == 0 {
		return nil, nil
	}
	return items[0], nil
}

func (q *OptionQuery) Count(ctx context.Context) (int, error) {
	spec := runtime.AggregateSpec{
		Table:      "options",
		Predicates: q.predicates,
		Aggregate:  runtime.Aggregate{Func: runtime.AggCount, Column: "*"},
	}
	row := q.db.Aggregate(ctx, spec)
	var out int
	if err := row.Scan(&out); err != nil {
		return out, err
	}
	return out, nil
}

func (q *OptionQuery) clone() *OptionQuery {
	cp := *q
	if len(q.predicates) > 0 {
		cp.predicates = append([]runtime.Predicate(nil), q.predicates...)
	}
	if len(q.orders) > 0 {
		cp.orders = append([]runtime.Order(nil), q.orders...)
	}
	if q.limit != nil {
		limit := *q.limit
		cp.limit = &limit
	}
	return &cp
}

func (q *OptionQuery) effectiveLimit() int {
	if q.limit != nil {
		limit := *q.limit
		if q.maxLimit > 0 && limit > q.maxLimit {
			return q.maxLimit
		}
		return limit
	}
	limit := q.defaultLimit
	if limit <= 0 && q.maxLimit > 0 {
		return q.maxLimit
	}
	if q.maxLimit > 0 && limit > q.maxLimit {
		return q.maxLimit
	}
	return limit
}

const postInsertQuery = `INSERT INTO posts (id, author_id, featured_media_id, title, slug, status, type, excerpt, content, seo, published_at, created_at, updated_at) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13) RETURNING id, author_id, featured_media_id, title, slug, status, type, excerpt, content, seo, published_at, created_at, updated_at`
const postSelectQuery = `SELECT id, author_id, featured_media_id, title, slug, status, type, excerpt, content, seo, published_at, created_at, updated_at FROM posts WHERE id = $1`
const postListQuery = `SELECT id, author_id, featured_media_id, title, slug, status, type, excerpt, content, seo, published_at, created_at, updated_at FROM posts ORDER BY id LIMIT $1 OFFSET $2`
const postUpdateQuery = `UPDATE posts SET author_id = $1, featured_media_id = $2, title = $3, slug = $4, status = $5, type = $6, excerpt = $7, content = $8, seo = $9, published_at = $10, updated_at = $11 WHERE id = $12 RETURNING id, author_id, featured_media_id, title, slug, status, type, excerpt, content, seo, published_at, created_at, updated_at`
const postCountQuery = `SELECT COUNT(*) FROM posts`
const postDeleteQuery = `DELETE FROM posts WHERE id = $1`

type PostClient struct {
	db    *pg.DB
	cache cache.Store
}

func (c *PostClient) Create(ctx context.Context, input *Post) (*Post, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	now := time.Now().UTC()
	if input.ID == "" {
		v, err := id.NewV7()
		if err != nil {
			return nil, err
		}
		input.ID = v
	}
	if input.CreatedAt.IsZero() {
		input.CreatedAt = now
	}
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Post", validation.OpCreate, postValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, postInsertQuery, input.ID, input.AuthorID, input.FeaturedMediaID, input.Title, input.Slug, input.Status, input.Type, input.Excerpt, input.Content, input.Seo, input.PublishedAt, input.CreatedAt, input.UpdatedAt)
	out := new(Post)
	if err := row.Scan(&out.ID, &out.AuthorID, &out.FeaturedMediaID, &out.Title, &out.Slug, &out.Status, &out.Type, &out.Excerpt, &out.Content, &out.Seo, &out.PublishedAt, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Post", out.ID), out)
	}
	return out, nil
}

func (c *PostClient) BulkCreate(ctx context.Context, inputs []*Post) ([]*Post, error) {
	if len(inputs) == 0 {
		return []*Post{}, nil
	}
	rowsSpec := make([][]any, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		now := time.Now().UTC()
		if input.ID == "" {
			v, err := id.NewV7()
			if err != nil {
				return nil, err
			}
			input.ID = v
		}
		if input.CreatedAt.IsZero() {
			input.CreatedAt = now
		}
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Post", validation.OpCreate, postValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := []any{input.ID, input.AuthorID, input.FeaturedMediaID, input.Title, input.Slug, input.Status, input.Type, input.Excerpt, input.Content, input.Seo, input.PublishedAt, input.CreatedAt, input.UpdatedAt}
		rowsSpec = append(rowsSpec, row)
	}
	spec := runtime.BulkInsertSpec{
		Table:     "posts",
		Columns:   []string{"id", "author_id", "featured_media_id", "title", "slug", "status", "type", "excerpt", "content", "seo", "published_at", "created_at", "updated_at"},
		Returning: []string{"id", "author_id", "featured_media_id", "title", "slug", "status", "type", "excerpt", "content", "seo", "published_at", "created_at", "updated_at"},
		Rows:      rowsSpec,
	}
	sql, args, err := runtime.BuildBulkInsertSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var created []*Post
	for rows.Next() {
		item := new(Post)
		if err := rows.Scan(&item.ID, &item.AuthorID, &item.FeaturedMediaID, &item.Title, &item.Slug, &item.Status, &item.Type, &item.Excerpt, &item.Content, &item.Seo, &item.PublishedAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		created = append(created, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Post", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return created, nil
}

func (c *PostClient) ByID(ctx context.Context, id string) (*Post, error) {
	var cachedKey string
	if c.cache != nil {
		cachedKey = makeCacheKey("Post", id)
		if value, ok, err := c.cache.Get(ctx, cachedKey); err != nil {
			return nil, err
		} else if ok {
			if entity, ok := value.(*Post); ok {
				return entity, nil
			}
		}
	}
	row := c.db.Pool.QueryRow(ctx, postSelectQuery, id)
	out := new(Post)
	if err := row.Scan(&out.ID, &out.AuthorID, &out.FeaturedMediaID, &out.Title, &out.Slug, &out.Status, &out.Type, &out.Excerpt, &out.Content, &out.Seo, &out.PublishedAt, &out.CreatedAt, &out.UpdatedAt); err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, nil
		}
		return nil, err
	}
	if c.cache != nil {
		cachedKey = makeCacheKey("Post", out.ID)
		_ = c.cache.Set(ctx, cachedKey, out)
	}
	return out, nil
}

func (c *PostClient) List(ctx context.Context, limit, offset int) ([]*Post, error) {
	if limit <= 0 {
		limit = 20
	}
	if offset < 0 {
		offset = 0
	}
	rows, err := c.db.Pool.Query(ctx, postListQuery, limit, offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Post
	for rows.Next() {
		item := new(Post)
		if err := rows.Scan(&item.ID, &item.AuthorID, &item.FeaturedMediaID, &item.Title, &item.Slug, &item.Status, &item.Type, &item.Excerpt, &item.Content, &item.Seo, &item.PublishedAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (c *PostClient) Count(ctx context.Context) (int, error) {
	row := c.db.Pool.QueryRow(ctx, postCountQuery)
	var total int
	if err := row.Scan(&total); err != nil {
		return 0, err
	}
	return total, nil
}

func (c *PostClient) Update(ctx context.Context, input *Post) (*Post, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	if input.ID == "" {
		return nil, errors.New("id is required")
	}
	now := time.Now().UTC()
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Post", validation.OpUpdate, postValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, postUpdateQuery, input.AuthorID, input.FeaturedMediaID, input.Title, input.Slug, input.Status, input.Type, input.Excerpt, input.Content, input.Seo, input.PublishedAt, input.UpdatedAt, input.ID)
	out := new(Post)
	if err := row.Scan(&out.ID, &out.AuthorID, &out.FeaturedMediaID, &out.Title, &out.Slug, &out.Status, &out.Type, &out.Excerpt, &out.Content, &out.Seo, &out.PublishedAt, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Post", out.ID), out)
	}
	return out, nil
}

func (c *PostClient) BulkUpdate(ctx context.Context, inputs []*Post) ([]*Post, error) {
	if len(inputs) == 0 {
		return []*Post{}, nil
	}
	specs := make([]runtime.BulkUpdateRow, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		if input.ID == "" {
			return nil, errors.New("id is required")
		}
		now := time.Now().UTC()
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Post", validation.OpUpdate, postValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := runtime.BulkUpdateRow{
			Primary: input.ID,
			Values:  []any{input.AuthorID, input.FeaturedMediaID, input.Title, input.Slug, input.Status, input.Type, input.Excerpt, input.Content, input.Seo, input.PublishedAt, input.UpdatedAt},
		}
		specs = append(specs, row)
	}
	spec := runtime.BulkUpdateSpec{
		Table:         "posts",
		PrimaryColumn: "id",
		Columns:       []string{"author_id", "featured_media_id", "title", "slug", "status", "type", "excerpt", "content", "seo", "published_at", "updated_at"},
		Returning:     []string{"id", "author_id", "featured_media_id", "title", "slug", "status", "type", "excerpt", "content", "seo", "published_at", "created_at", "updated_at"},
		Rows:          specs,
	}
	sql, args, err := runtime.BuildBulkUpdateSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var updated []*Post
	for rows.Next() {
		item := new(Post)
		if err := rows.Scan(&item.ID, &item.AuthorID, &item.FeaturedMediaID, &item.Title, &item.Slug, &item.Status, &item.Type, &item.Excerpt, &item.Content, &item.Seo, &item.PublishedAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		updated = append(updated, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Post", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return updated, nil
}

func (c *PostClient) Delete(ctx context.Context, id string) error {
	if _, err := c.db.Pool.Exec(ctx, postDeleteQuery, id); err != nil {
		return err
	}
	if c.cache != nil {
		_ = c.cache.Delete(ctx, makeCacheKey("Post", id))
	}
	return nil
}

func (c *PostClient) BulkDelete(ctx context.Context, ids []string) (int64, error) {
	if len(ids) == 0 {
		return 0, nil
	}
	spec := runtime.BulkDeleteSpec{
		Table:         "posts",
		PrimaryColumn: "id",
		IDs:           make([]any, len(ids)),
	}
	for i, id := range ids {
		spec.IDs[i] = id
	}
	sql, args, err := runtime.BuildBulkDeleteSQL(spec)
	if err != nil {
		return 0, err
	}
	tag, err := c.db.Pool.Exec(ctx, sql, args...)
	if err != nil {
		return 0, err
	}
	if c.cache != nil {
		for _, id := range ids {
			_ = c.cache.Delete(ctx, makeCacheKey("Post", id))
		}
	}
	return int64(tag.RowsAffected()), nil
}

type PostQuery struct {
	db           *pg.DB
	predicates   []runtime.Predicate
	orders       []runtime.Order
	limit        *int
	offset       int
	defaultLimit int
	maxLimit     int
}

func (c *PostClient) Query() *PostQuery {
	return &PostQuery{db: c.db, defaultLimit: 20, maxLimit: 200}
}

func (q *PostQuery) Limit(n int) *PostQuery {
	if n <= 0 {
		q.limit = nil
		return q
	}
	q.limit = &n
	return q
}

func (q *PostQuery) Offset(n int) *PostQuery {
	if n < 0 {
		return q
	}
	q.offset = n
	return q
}

func (q *PostQuery) WhereIDEq(value string) *PostQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "id", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *PostQuery) WhereSlugEq(value string) *PostQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "slug", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *PostQuery) WhereAuthorIDEq(value string) *PostQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "author_id", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *PostQuery) WhereStatusEq(value string) *PostQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "status", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *PostQuery) WhereTypeEq(value string) *PostQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "type", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *PostQuery) OrderByPublishedAtDesc() *PostQuery {
	q.orders = append(q.orders, runtime.Order{Column: "published_at", Direction: runtime.SortDesc})
	return q
}

func (q *PostQuery) OrderByCreatedAtDesc() *PostQuery {
	q.orders = append(q.orders, runtime.Order{Column: "created_at", Direction: runtime.SortDesc})
	return q
}

func (q *PostQuery) All(ctx context.Context) ([]*Post, error) {
	spec := runtime.SelectSpec{
		Table:      "posts",
		Columns:    []string{"id", "author_id", "featured_media_id", "title", "slug", "status", "type", "excerpt", "content", "seo", "published_at", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Post
	for rows.Next() {
		item := new(Post)
		if err := rows.Scan(&item.ID, &item.AuthorID, &item.FeaturedMediaID, &item.Title, &item.Slug, &item.Status, &item.Type, &item.Excerpt, &item.Content, &item.Seo, &item.PublishedAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (q *PostQuery) Stream(ctx context.Context) (*runtime.Stream[*Post], error) {
	spec := runtime.SelectSpec{
		Table:      "posts",
		Columns:    []string{"id", "author_id", "featured_media_id", "title", "slug", "status", "type", "excerpt", "content", "seo", "published_at", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	stream := runtime.NewStream[*Post](rows, func(rows pgx.Rows) (*Post, error) {
		item := new(Post)
		if err := rows.Scan(&item.ID, &item.AuthorID, &item.FeaturedMediaID, &item.Title, &item.Slug, &item.Status, &item.Type, &item.Excerpt, &item.Content, &item.Seo, &item.PublishedAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		return item, nil
	})
	return stream, nil
}

func (q *PostQuery) First(ctx context.Context) (*Post, error) {
	clone := q.clone()
	one := 1
	clone.limit = &one
	items, err := clone.All(ctx)
	if err != nil {
		return nil, err
	}
	if len(items) == 0 {
		return nil, nil
	}
	return items[0], nil
}

func (q *PostQuery) Count(ctx context.Context) (int, error) {
	spec := runtime.AggregateSpec{
		Table:      "posts",
		Predicates: q.predicates,
		Aggregate:  runtime.Aggregate{Func: runtime.AggCount, Column: "*"},
	}
	row := q.db.Aggregate(ctx, spec)
	var out int
	if err := row.Scan(&out); err != nil {
		return out, err
	}
	return out, nil
}

func (q *PostQuery) clone() *PostQuery {
	cp := *q
	if len(q.predicates) > 0 {
		cp.predicates = append([]runtime.Predicate(nil), q.predicates...)
	}
	if len(q.orders) > 0 {
		cp.orders = append([]runtime.Order(nil), q.orders...)
	}
	if q.limit != nil {
		limit := *q.limit
		cp.limit = &limit
	}
	return &cp
}

func (q *PostQuery) effectiveLimit() int {
	if q.limit != nil {
		limit := *q.limit
		if q.maxLimit > 0 && limit > q.maxLimit {
			return q.maxLimit
		}
		return limit
	}
	limit := q.defaultLimit
	if limit <= 0 && q.maxLimit > 0 {
		return q.maxLimit
	}
	if q.maxLimit > 0 && limit > q.maxLimit {
		return q.maxLimit
	}
	return limit
}

const postAuthorRelationQuery = `SELECT id, username, email, password_hash, display_name, bio, avatar_url, website_url, last_login_at, created_at, updated_at FROM users WHERE id IN (%s)`

func (c *PostClient) LoadAuthor(ctx context.Context, parents ...*Post) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensurePostEdges(parent)
		edges.markLoaded("author")
		var fk keyType
		fk = parent.AuthorID
		if isZero(fk) {
			edges.Author = nil
			continue
		}
		if _, ok := seen[fk]; !ok {
			seen[fk] = struct{}{}
			keys = append(keys, fk)
		}
	}
	if len(keys) == 0 {
		return nil
	}
	sql, args := buildInQuery(postAuthorRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	related := make(map[keyType]*User, len(keys))
	for rows.Next() {
		item := new(User)
		if err := rows.Scan(&item.ID, &item.Username, &item.Email, &item.PasswordHash, &item.DisplayName, &item.Bio, &item.AvatarURL, &item.WebsiteURL, &item.LastLoginAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return err
		}
		key := item.ID
		related[key] = item
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensurePostEdges(parent)
		var fk keyType
		fk = parent.AuthorID
		if isZero(fk) {
			edges.Author = nil
			continue
		}
		if item, ok := related[fk]; ok {
			edges.Author = item
		} else {
			edges.Author = nil
		}
	}
	return nil
}

const postFeaturedMediaRelationQuery = `SELECT id, uploaded_by_id, file_name, mime_type, storage_key, url, title, alt_text, caption, description, file_size_bytes, metadata, created_at, updated_at FROM medias WHERE id IN (%s)`

func (c *PostClient) LoadFeaturedMedia(ctx context.Context, parents ...*Post) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensurePostEdges(parent)
		edges.markLoaded("featured_media")
		var fk keyType
		fkPtr := parent.FeaturedMediaID
		if fkPtr == nil {
			edges.FeaturedMedia = nil
			continue
		}
		fk = *fkPtr
		if isZero(fk) {
			edges.FeaturedMedia = nil
			continue
		}
		if _, ok := seen[fk]; !ok {
			seen[fk] = struct{}{}
			keys = append(keys, fk)
		}
	}
	if len(keys) == 0 {
		return nil
	}
	sql, args := buildInQuery(postFeaturedMediaRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	related := make(map[keyType]*Media, len(keys))
	for rows.Next() {
		item := new(Media)
		if err := rows.Scan(&item.ID, &item.UploadedByID, &item.FileName, &item.MimeType, &item.StorageKey, &item.URL, &item.Title, &item.AltText, &item.Caption, &item.Description, &item.FileSizeBytes, &item.Metadata, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return err
		}
		key := item.ID
		related[key] = item
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensurePostEdges(parent)
		var fk keyType
		fkPtr := parent.FeaturedMediaID
		if fkPtr == nil {
			edges.FeaturedMedia = nil
			continue
		}
		fk = *fkPtr
		if isZero(fk) {
			edges.FeaturedMedia = nil
			continue
		}
		if item, ok := related[fk]; ok {
			edges.FeaturedMedia = item
		} else {
			edges.FeaturedMedia = nil
		}
	}
	return nil
}

const postCategoriesRelationQuery = `SELECT id, name, slug, description, parent_id, created_at, updated_at, jt.post_id FROM categories AS t JOIN post_categories AS jt ON t.id = jt.category_id WHERE jt.post_id IN (%s)`

func (c *PostClient) LoadCategories(ctx context.Context, parents ...*Post) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	buckets := make(map[keyType][]*Post, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		key := parent.ID
		if isZero(key) {
			edges := ensurePostEdges(parent)
			if edges.Categories == nil {
				edges.Categories = []*Category{}
			}
			edges.markLoaded("categories")
			continue
		}
		if _, ok := seen[key]; !ok {
			seen[key] = struct{}{}
			keys = append(keys, key)
		}
		buckets[key] = append(buckets[key], parent)
	}
	if len(keys) == 0 {
		for _, parent := range parents {
			if parent == nil {
				continue
			}
			edges := ensurePostEdges(parent)
			if edges.Categories == nil {
				edges.Categories = []*Category{}
			}
			edges.markLoaded("categories")
		}
		return nil
	}
	sql, args := buildInQuery(postCategoriesRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	for rows.Next() {
		item := new(Category)
		var owner keyType
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.ParentID, &item.CreatedAt, &item.UpdatedAt, &owner); err != nil {
			return err
		}
		parents, ok := buckets[owner]
		if !ok {
			continue
		}
		for _, parent := range parents {
			edges := ensurePostEdges(parent)
			edges.Categories = append(edges.Categories, item)
		}
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensurePostEdges(parent)
		if edges.Categories == nil {
			edges.Categories = []*Category{}
		}
		edges.markLoaded("categories")
	}
	return nil
}

const postTagsRelationQuery = `SELECT id, name, slug, description, created_at, updated_at, jt.post_id FROM tags AS t JOIN post_tags AS jt ON t.id = jt.tag_id WHERE jt.post_id IN (%s)`

func (c *PostClient) LoadTags(ctx context.Context, parents ...*Post) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	buckets := make(map[keyType][]*Post, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		key := parent.ID
		if isZero(key) {
			edges := ensurePostEdges(parent)
			if edges.Tags == nil {
				edges.Tags = []*Tag{}
			}
			edges.markLoaded("tags")
			continue
		}
		if _, ok := seen[key]; !ok {
			seen[key] = struct{}{}
			keys = append(keys, key)
		}
		buckets[key] = append(buckets[key], parent)
	}
	if len(keys) == 0 {
		for _, parent := range parents {
			if parent == nil {
				continue
			}
			edges := ensurePostEdges(parent)
			if edges.Tags == nil {
				edges.Tags = []*Tag{}
			}
			edges.markLoaded("tags")
		}
		return nil
	}
	sql, args := buildInQuery(postTagsRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	for rows.Next() {
		item := new(Tag)
		var owner keyType
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.CreatedAt, &item.UpdatedAt, &owner); err != nil {
			return err
		}
		parents, ok := buckets[owner]
		if !ok {
			continue
		}
		for _, parent := range parents {
			edges := ensurePostEdges(parent)
			edges.Tags = append(edges.Tags, item)
		}
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensurePostEdges(parent)
		if edges.Tags == nil {
			edges.Tags = []*Tag{}
		}
		edges.markLoaded("tags")
	}
	return nil
}

const roleInsertQuery = `INSERT INTO roles (id, name, slug, description, capabilities, created_at, updated_at) VALUES ($1, $2, $3, $4, $5, $6, $7) RETURNING id, name, slug, description, capabilities, created_at, updated_at`
const roleSelectQuery = `SELECT id, name, slug, description, capabilities, created_at, updated_at FROM roles WHERE id = $1`
const roleListQuery = `SELECT id, name, slug, description, capabilities, created_at, updated_at FROM roles ORDER BY id LIMIT $1 OFFSET $2`
const roleUpdateQuery = `UPDATE roles SET name = $1, slug = $2, description = $3, capabilities = $4, updated_at = $5 WHERE id = $6 RETURNING id, name, slug, description, capabilities, created_at, updated_at`
const roleCountQuery = `SELECT COUNT(*) FROM roles`
const roleDeleteQuery = `DELETE FROM roles WHERE id = $1`

type RoleClient struct {
	db    *pg.DB
	cache cache.Store
}

func (c *RoleClient) Create(ctx context.Context, input *Role) (*Role, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	now := time.Now().UTC()
	if input.ID == "" {
		v, err := id.NewV7()
		if err != nil {
			return nil, err
		}
		input.ID = v
	}
	if input.CreatedAt.IsZero() {
		input.CreatedAt = now
	}
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Role", validation.OpCreate, roleValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, roleInsertQuery, input.ID, input.Name, input.Slug, input.Description, input.Capabilities, input.CreatedAt, input.UpdatedAt)
	out := new(Role)
	if err := row.Scan(&out.ID, &out.Name, &out.Slug, &out.Description, &out.Capabilities, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Role", out.ID), out)
	}
	return out, nil
}

func (c *RoleClient) BulkCreate(ctx context.Context, inputs []*Role) ([]*Role, error) {
	if len(inputs) == 0 {
		return []*Role{}, nil
	}
	rowsSpec := make([][]any, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		now := time.Now().UTC()
		if input.ID == "" {
			v, err := id.NewV7()
			if err != nil {
				return nil, err
			}
			input.ID = v
		}
		if input.CreatedAt.IsZero() {
			input.CreatedAt = now
		}
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Role", validation.OpCreate, roleValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := []any{input.ID, input.Name, input.Slug, input.Description, input.Capabilities, input.CreatedAt, input.UpdatedAt}
		rowsSpec = append(rowsSpec, row)
	}
	spec := runtime.BulkInsertSpec{
		Table:     "roles",
		Columns:   []string{"id", "name", "slug", "description", "capabilities", "created_at", "updated_at"},
		Returning: []string{"id", "name", "slug", "description", "capabilities", "created_at", "updated_at"},
		Rows:      rowsSpec,
	}
	sql, args, err := runtime.BuildBulkInsertSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var created []*Role
	for rows.Next() {
		item := new(Role)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.Capabilities, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		created = append(created, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Role", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return created, nil
}

func (c *RoleClient) ByID(ctx context.Context, id string) (*Role, error) {
	var cachedKey string
	if c.cache != nil {
		cachedKey = makeCacheKey("Role", id)
		if value, ok, err := c.cache.Get(ctx, cachedKey); err != nil {
			return nil, err
		} else if ok {
			if entity, ok := value.(*Role); ok {
				return entity, nil
			}
		}
	}
	row := c.db.Pool.QueryRow(ctx, roleSelectQuery, id)
	out := new(Role)
	if err := row.Scan(&out.ID, &out.Name, &out.Slug, &out.Description, &out.Capabilities, &out.CreatedAt, &out.UpdatedAt); err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, nil
		}
		return nil, err
	}
	if c.cache != nil {
		cachedKey = makeCacheKey("Role", out.ID)
		_ = c.cache.Set(ctx, cachedKey, out)
	}
	return out, nil
}

func (c *RoleClient) List(ctx context.Context, limit, offset int) ([]*Role, error) {
	if limit <= 0 {
		limit = 20
	}
	if offset < 0 {
		offset = 0
	}
	rows, err := c.db.Pool.Query(ctx, roleListQuery, limit, offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Role
	for rows.Next() {
		item := new(Role)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.Capabilities, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (c *RoleClient) Count(ctx context.Context) (int, error) {
	row := c.db.Pool.QueryRow(ctx, roleCountQuery)
	var total int
	if err := row.Scan(&total); err != nil {
		return 0, err
	}
	return total, nil
}

func (c *RoleClient) Update(ctx context.Context, input *Role) (*Role, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	if input.ID == "" {
		return nil, errors.New("id is required")
	}
	now := time.Now().UTC()
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Role", validation.OpUpdate, roleValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, roleUpdateQuery, input.Name, input.Slug, input.Description, input.Capabilities, input.UpdatedAt, input.ID)
	out := new(Role)
	if err := row.Scan(&out.ID, &out.Name, &out.Slug, &out.Description, &out.Capabilities, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Role", out.ID), out)
	}
	return out, nil
}

func (c *RoleClient) BulkUpdate(ctx context.Context, inputs []*Role) ([]*Role, error) {
	if len(inputs) == 0 {
		return []*Role{}, nil
	}
	specs := make([]runtime.BulkUpdateRow, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		if input.ID == "" {
			return nil, errors.New("id is required")
		}
		now := time.Now().UTC()
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Role", validation.OpUpdate, roleValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := runtime.BulkUpdateRow{
			Primary: input.ID,
			Values:  []any{input.Name, input.Slug, input.Description, input.Capabilities, input.UpdatedAt},
		}
		specs = append(specs, row)
	}
	spec := runtime.BulkUpdateSpec{
		Table:         "roles",
		PrimaryColumn: "id",
		Columns:       []string{"name", "slug", "description", "capabilities", "updated_at"},
		Returning:     []string{"id", "name", "slug", "description", "capabilities", "created_at", "updated_at"},
		Rows:          specs,
	}
	sql, args, err := runtime.BuildBulkUpdateSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var updated []*Role
	for rows.Next() {
		item := new(Role)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.Capabilities, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		updated = append(updated, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Role", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return updated, nil
}

func (c *RoleClient) Delete(ctx context.Context, id string) error {
	if _, err := c.db.Pool.Exec(ctx, roleDeleteQuery, id); err != nil {
		return err
	}
	if c.cache != nil {
		_ = c.cache.Delete(ctx, makeCacheKey("Role", id))
	}
	return nil
}

func (c *RoleClient) BulkDelete(ctx context.Context, ids []string) (int64, error) {
	if len(ids) == 0 {
		return 0, nil
	}
	spec := runtime.BulkDeleteSpec{
		Table:         "roles",
		PrimaryColumn: "id",
		IDs:           make([]any, len(ids)),
	}
	for i, id := range ids {
		spec.IDs[i] = id
	}
	sql, args, err := runtime.BuildBulkDeleteSQL(spec)
	if err != nil {
		return 0, err
	}
	tag, err := c.db.Pool.Exec(ctx, sql, args...)
	if err != nil {
		return 0, err
	}
	if c.cache != nil {
		for _, id := range ids {
			_ = c.cache.Delete(ctx, makeCacheKey("Role", id))
		}
	}
	return int64(tag.RowsAffected()), nil
}

type RoleQuery struct {
	db           *pg.DB
	predicates   []runtime.Predicate
	orders       []runtime.Order
	limit        *int
	offset       int
	defaultLimit int
	maxLimit     int
}

func (c *RoleClient) Query() *RoleQuery {
	return &RoleQuery{db: c.db, defaultLimit: 50, maxLimit: 200}
}

func (q *RoleQuery) Limit(n int) *RoleQuery {
	if n <= 0 {
		q.limit = nil
		return q
	}
	q.limit = &n
	return q
}

func (q *RoleQuery) Offset(n int) *RoleQuery {
	if n < 0 {
		return q
	}
	q.offset = n
	return q
}

func (q *RoleQuery) WhereIDEq(value string) *RoleQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "id", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *RoleQuery) WhereSlugEq(value string) *RoleQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "slug", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *RoleQuery) OrderByCreatedAtDesc() *RoleQuery {
	q.orders = append(q.orders, runtime.Order{Column: "created_at", Direction: runtime.SortDesc})
	return q
}

func (q *RoleQuery) OrderBySlugAsc() *RoleQuery {
	q.orders = append(q.orders, runtime.Order{Column: "slug", Direction: runtime.SortAsc})
	return q
}

func (q *RoleQuery) All(ctx context.Context) ([]*Role, error) {
	spec := runtime.SelectSpec{
		Table:      "roles",
		Columns:    []string{"id", "name", "slug", "description", "capabilities", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Role
	for rows.Next() {
		item := new(Role)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.Capabilities, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (q *RoleQuery) Stream(ctx context.Context) (*runtime.Stream[*Role], error) {
	spec := runtime.SelectSpec{
		Table:      "roles",
		Columns:    []string{"id", "name", "slug", "description", "capabilities", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	stream := runtime.NewStream[*Role](rows, func(rows pgx.Rows) (*Role, error) {
		item := new(Role)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.Capabilities, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		return item, nil
	})
	return stream, nil
}

func (q *RoleQuery) First(ctx context.Context) (*Role, error) {
	clone := q.clone()
	one := 1
	clone.limit = &one
	items, err := clone.All(ctx)
	if err != nil {
		return nil, err
	}
	if len(items) == 0 {
		return nil, nil
	}
	return items[0], nil
}

func (q *RoleQuery) Count(ctx context.Context) (int, error) {
	spec := runtime.AggregateSpec{
		Table:      "roles",
		Predicates: q.predicates,
		Aggregate:  runtime.Aggregate{Func: runtime.AggCount, Column: "*"},
	}
	row := q.db.Aggregate(ctx, spec)
	var out int
	if err := row.Scan(&out); err != nil {
		return out, err
	}
	return out, nil
}

func (q *RoleQuery) clone() *RoleQuery {
	cp := *q
	if len(q.predicates) > 0 {
		cp.predicates = append([]runtime.Predicate(nil), q.predicates...)
	}
	if len(q.orders) > 0 {
		cp.orders = append([]runtime.Order(nil), q.orders...)
	}
	if q.limit != nil {
		limit := *q.limit
		cp.limit = &limit
	}
	return &cp
}

func (q *RoleQuery) effectiveLimit() int {
	if q.limit != nil {
		limit := *q.limit
		if q.maxLimit > 0 && limit > q.maxLimit {
			return q.maxLimit
		}
		return limit
	}
	limit := q.defaultLimit
	if limit <= 0 && q.maxLimit > 0 {
		return q.maxLimit
	}
	if q.maxLimit > 0 && limit > q.maxLimit {
		return q.maxLimit
	}
	return limit
}

const roleUsersRelationQuery = `SELECT id, username, email, password_hash, display_name, bio, avatar_url, website_url, last_login_at, created_at, updated_at, jt.role_id FROM users AS t JOIN user_roles AS jt ON t.id = jt.user_id WHERE jt.role_id IN (%s)`

func (c *RoleClient) LoadUsers(ctx context.Context, parents ...*Role) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	buckets := make(map[keyType][]*Role, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		key := parent.ID
		if isZero(key) {
			edges := ensureRoleEdges(parent)
			if edges.Users == nil {
				edges.Users = []*User{}
			}
			edges.markLoaded("users")
			continue
		}
		if _, ok := seen[key]; !ok {
			seen[key] = struct{}{}
			keys = append(keys, key)
		}
		buckets[key] = append(buckets[key], parent)
	}
	if len(keys) == 0 {
		for _, parent := range parents {
			if parent == nil {
				continue
			}
			edges := ensureRoleEdges(parent)
			if edges.Users == nil {
				edges.Users = []*User{}
			}
			edges.markLoaded("users")
		}
		return nil
	}
	sql, args := buildInQuery(roleUsersRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	for rows.Next() {
		item := new(User)
		var owner keyType
		if err := rows.Scan(&item.ID, &item.Username, &item.Email, &item.PasswordHash, &item.DisplayName, &item.Bio, &item.AvatarURL, &item.WebsiteURL, &item.LastLoginAt, &item.CreatedAt, &item.UpdatedAt, &owner); err != nil {
			return err
		}
		parents, ok := buckets[owner]
		if !ok {
			continue
		}
		for _, parent := range parents {
			edges := ensureRoleEdges(parent)
			edges.Users = append(edges.Users, item)
		}
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureRoleEdges(parent)
		if edges.Users == nil {
			edges.Users = []*User{}
		}
		edges.markLoaded("users")
	}
	return nil
}

const tagInsertQuery = `INSERT INTO tags (id, name, slug, description, created_at, updated_at) VALUES ($1, $2, $3, $4, $5, $6) RETURNING id, name, slug, description, created_at, updated_at`
const tagSelectQuery = `SELECT id, name, slug, description, created_at, updated_at FROM tags WHERE id = $1`
const tagListQuery = `SELECT id, name, slug, description, created_at, updated_at FROM tags ORDER BY id LIMIT $1 OFFSET $2`
const tagUpdateQuery = `UPDATE tags SET name = $1, slug = $2, description = $3, updated_at = $4 WHERE id = $5 RETURNING id, name, slug, description, created_at, updated_at`
const tagCountQuery = `SELECT COUNT(*) FROM tags`
const tagDeleteQuery = `DELETE FROM tags WHERE id = $1`

type TagClient struct {
	db    *pg.DB
	cache cache.Store
}

func (c *TagClient) Create(ctx context.Context, input *Tag) (*Tag, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	now := time.Now().UTC()
	if input.ID == "" {
		v, err := id.NewV7()
		if err != nil {
			return nil, err
		}
		input.ID = v
	}
	if input.CreatedAt.IsZero() {
		input.CreatedAt = now
	}
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Tag", validation.OpCreate, tagValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, tagInsertQuery, input.ID, input.Name, input.Slug, input.Description, input.CreatedAt, input.UpdatedAt)
	out := new(Tag)
	if err := row.Scan(&out.ID, &out.Name, &out.Slug, &out.Description, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Tag", out.ID), out)
	}
	return out, nil
}

func (c *TagClient) BulkCreate(ctx context.Context, inputs []*Tag) ([]*Tag, error) {
	if len(inputs) == 0 {
		return []*Tag{}, nil
	}
	rowsSpec := make([][]any, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		now := time.Now().UTC()
		if input.ID == "" {
			v, err := id.NewV7()
			if err != nil {
				return nil, err
			}
			input.ID = v
		}
		if input.CreatedAt.IsZero() {
			input.CreatedAt = now
		}
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Tag", validation.OpCreate, tagValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := []any{input.ID, input.Name, input.Slug, input.Description, input.CreatedAt, input.UpdatedAt}
		rowsSpec = append(rowsSpec, row)
	}
	spec := runtime.BulkInsertSpec{
		Table:     "tags",
		Columns:   []string{"id", "name", "slug", "description", "created_at", "updated_at"},
		Returning: []string{"id", "name", "slug", "description", "created_at", "updated_at"},
		Rows:      rowsSpec,
	}
	sql, args, err := runtime.BuildBulkInsertSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var created []*Tag
	for rows.Next() {
		item := new(Tag)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		created = append(created, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Tag", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return created, nil
}

func (c *TagClient) ByID(ctx context.Context, id string) (*Tag, error) {
	var cachedKey string
	if c.cache != nil {
		cachedKey = makeCacheKey("Tag", id)
		if value, ok, err := c.cache.Get(ctx, cachedKey); err != nil {
			return nil, err
		} else if ok {
			if entity, ok := value.(*Tag); ok {
				return entity, nil
			}
		}
	}
	row := c.db.Pool.QueryRow(ctx, tagSelectQuery, id)
	out := new(Tag)
	if err := row.Scan(&out.ID, &out.Name, &out.Slug, &out.Description, &out.CreatedAt, &out.UpdatedAt); err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, nil
		}
		return nil, err
	}
	if c.cache != nil {
		cachedKey = makeCacheKey("Tag", out.ID)
		_ = c.cache.Set(ctx, cachedKey, out)
	}
	return out, nil
}

func (c *TagClient) List(ctx context.Context, limit, offset int) ([]*Tag, error) {
	if limit <= 0 {
		limit = 20
	}
	if offset < 0 {
		offset = 0
	}
	rows, err := c.db.Pool.Query(ctx, tagListQuery, limit, offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Tag
	for rows.Next() {
		item := new(Tag)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (c *TagClient) Count(ctx context.Context) (int, error) {
	row := c.db.Pool.QueryRow(ctx, tagCountQuery)
	var total int
	if err := row.Scan(&total); err != nil {
		return 0, err
	}
	return total, nil
}

func (c *TagClient) Update(ctx context.Context, input *Tag) (*Tag, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	if input.ID == "" {
		return nil, errors.New("id is required")
	}
	now := time.Now().UTC()
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "Tag", validation.OpUpdate, tagValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, tagUpdateQuery, input.Name, input.Slug, input.Description, input.UpdatedAt, input.ID)
	out := new(Tag)
	if err := row.Scan(&out.ID, &out.Name, &out.Slug, &out.Description, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("Tag", out.ID), out)
	}
	return out, nil
}

func (c *TagClient) BulkUpdate(ctx context.Context, inputs []*Tag) ([]*Tag, error) {
	if len(inputs) == 0 {
		return []*Tag{}, nil
	}
	specs := make([]runtime.BulkUpdateRow, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		if input.ID == "" {
			return nil, errors.New("id is required")
		}
		now := time.Now().UTC()
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "Tag", validation.OpUpdate, tagValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := runtime.BulkUpdateRow{
			Primary: input.ID,
			Values:  []any{input.Name, input.Slug, input.Description, input.UpdatedAt},
		}
		specs = append(specs, row)
	}
	spec := runtime.BulkUpdateSpec{
		Table:         "tags",
		PrimaryColumn: "id",
		Columns:       []string{"name", "slug", "description", "updated_at"},
		Returning:     []string{"id", "name", "slug", "description", "created_at", "updated_at"},
		Rows:          specs,
	}
	sql, args, err := runtime.BuildBulkUpdateSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var updated []*Tag
	for rows.Next() {
		item := new(Tag)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		updated = append(updated, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("Tag", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return updated, nil
}

func (c *TagClient) Delete(ctx context.Context, id string) error {
	if _, err := c.db.Pool.Exec(ctx, tagDeleteQuery, id); err != nil {
		return err
	}
	if c.cache != nil {
		_ = c.cache.Delete(ctx, makeCacheKey("Tag", id))
	}
	return nil
}

func (c *TagClient) BulkDelete(ctx context.Context, ids []string) (int64, error) {
	if len(ids) == 0 {
		return 0, nil
	}
	spec := runtime.BulkDeleteSpec{
		Table:         "tags",
		PrimaryColumn: "id",
		IDs:           make([]any, len(ids)),
	}
	for i, id := range ids {
		spec.IDs[i] = id
	}
	sql, args, err := runtime.BuildBulkDeleteSQL(spec)
	if err != nil {
		return 0, err
	}
	tag, err := c.db.Pool.Exec(ctx, sql, args...)
	if err != nil {
		return 0, err
	}
	if c.cache != nil {
		for _, id := range ids {
			_ = c.cache.Delete(ctx, makeCacheKey("Tag", id))
		}
	}
	return int64(tag.RowsAffected()), nil
}

type TagQuery struct {
	db           *pg.DB
	predicates   []runtime.Predicate
	orders       []runtime.Order
	limit        *int
	offset       int
	defaultLimit int
	maxLimit     int
}

func (c *TagClient) Query() *TagQuery {
	return &TagQuery{db: c.db, defaultLimit: 100, maxLimit: 500}
}

func (q *TagQuery) Limit(n int) *TagQuery {
	if n <= 0 {
		q.limit = nil
		return q
	}
	q.limit = &n
	return q
}

func (q *TagQuery) Offset(n int) *TagQuery {
	if n < 0 {
		return q
	}
	q.offset = n
	return q
}

func (q *TagQuery) WhereIDEq(value string) *TagQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "id", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *TagQuery) WhereSlugEq(value string) *TagQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "slug", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *TagQuery) OrderByNameAsc() *TagQuery {
	q.orders = append(q.orders, runtime.Order{Column: "name", Direction: runtime.SortAsc})
	return q
}

func (q *TagQuery) All(ctx context.Context) ([]*Tag, error) {
	spec := runtime.SelectSpec{
		Table:      "tags",
		Columns:    []string{"id", "name", "slug", "description", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*Tag
	for rows.Next() {
		item := new(Tag)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (q *TagQuery) Stream(ctx context.Context) (*runtime.Stream[*Tag], error) {
	spec := runtime.SelectSpec{
		Table:      "tags",
		Columns:    []string{"id", "name", "slug", "description", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	stream := runtime.NewStream[*Tag](rows, func(rows pgx.Rows) (*Tag, error) {
		item := new(Tag)
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		return item, nil
	})
	return stream, nil
}

func (q *TagQuery) First(ctx context.Context) (*Tag, error) {
	clone := q.clone()
	one := 1
	clone.limit = &one
	items, err := clone.All(ctx)
	if err != nil {
		return nil, err
	}
	if len(items) == 0 {
		return nil, nil
	}
	return items[0], nil
}

func (q *TagQuery) Count(ctx context.Context) (int, error) {
	spec := runtime.AggregateSpec{
		Table:      "tags",
		Predicates: q.predicates,
		Aggregate:  runtime.Aggregate{Func: runtime.AggCount, Column: "*"},
	}
	row := q.db.Aggregate(ctx, spec)
	var out int
	if err := row.Scan(&out); err != nil {
		return out, err
	}
	return out, nil
}

func (q *TagQuery) clone() *TagQuery {
	cp := *q
	if len(q.predicates) > 0 {
		cp.predicates = append([]runtime.Predicate(nil), q.predicates...)
	}
	if len(q.orders) > 0 {
		cp.orders = append([]runtime.Order(nil), q.orders...)
	}
	if q.limit != nil {
		limit := *q.limit
		cp.limit = &limit
	}
	return &cp
}

func (q *TagQuery) effectiveLimit() int {
	if q.limit != nil {
		limit := *q.limit
		if q.maxLimit > 0 && limit > q.maxLimit {
			return q.maxLimit
		}
		return limit
	}
	limit := q.defaultLimit
	if limit <= 0 && q.maxLimit > 0 {
		return q.maxLimit
	}
	if q.maxLimit > 0 && limit > q.maxLimit {
		return q.maxLimit
	}
	return limit
}

const tagPostsRelationQuery = `SELECT id, author_id, featured_media_id, title, slug, status, type, excerpt, content, seo, published_at, created_at, updated_at, jt.tag_id FROM posts AS t JOIN post_tags AS jt ON t.id = jt.post_id WHERE jt.tag_id IN (%s)`

func (c *TagClient) LoadPosts(ctx context.Context, parents ...*Tag) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	buckets := make(map[keyType][]*Tag, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		key := parent.ID
		if isZero(key) {
			edges := ensureTagEdges(parent)
			if edges.Posts == nil {
				edges.Posts = []*Post{}
			}
			edges.markLoaded("posts")
			continue
		}
		if _, ok := seen[key]; !ok {
			seen[key] = struct{}{}
			keys = append(keys, key)
		}
		buckets[key] = append(buckets[key], parent)
	}
	if len(keys) == 0 {
		for _, parent := range parents {
			if parent == nil {
				continue
			}
			edges := ensureTagEdges(parent)
			if edges.Posts == nil {
				edges.Posts = []*Post{}
			}
			edges.markLoaded("posts")
		}
		return nil
	}
	sql, args := buildInQuery(tagPostsRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	for rows.Next() {
		item := new(Post)
		var owner keyType
		if err := rows.Scan(&item.ID, &item.AuthorID, &item.FeaturedMediaID, &item.Title, &item.Slug, &item.Status, &item.Type, &item.Excerpt, &item.Content, &item.Seo, &item.PublishedAt, &item.CreatedAt, &item.UpdatedAt, &owner); err != nil {
			return err
		}
		parents, ok := buckets[owner]
		if !ok {
			continue
		}
		for _, parent := range parents {
			edges := ensureTagEdges(parent)
			edges.Posts = append(edges.Posts, item)
		}
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureTagEdges(parent)
		if edges.Posts == nil {
			edges.Posts = []*Post{}
		}
		edges.markLoaded("posts")
	}
	return nil
}

const userInsertQuery = `INSERT INTO users (id, username, email, password_hash, display_name, bio, avatar_url, website_url, last_login_at, created_at, updated_at) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11) RETURNING id, username, email, password_hash, display_name, bio, avatar_url, website_url, last_login_at, created_at, updated_at`
const userSelectQuery = `SELECT id, username, email, password_hash, display_name, bio, avatar_url, website_url, last_login_at, created_at, updated_at FROM users WHERE id = $1`
const userListQuery = `SELECT id, username, email, password_hash, display_name, bio, avatar_url, website_url, last_login_at, created_at, updated_at FROM users ORDER BY id LIMIT $1 OFFSET $2`
const userUpdateQuery = `UPDATE users SET username = $1, email = $2, password_hash = $3, display_name = $4, bio = $5, avatar_url = $6, website_url = $7, last_login_at = $8, updated_at = $9 WHERE id = $10 RETURNING id, username, email, password_hash, display_name, bio, avatar_url, website_url, last_login_at, created_at, updated_at`
const userCountQuery = `SELECT COUNT(*) FROM users`
const userDeleteQuery = `DELETE FROM users WHERE id = $1`

type UserClient struct {
	db    *pg.DB
	cache cache.Store
}

func (c *UserClient) Create(ctx context.Context, input *User) (*User, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	now := time.Now().UTC()
	if input.ID == "" {
		v, err := id.NewV7()
		if err != nil {
			return nil, err
		}
		input.ID = v
	}
	if input.CreatedAt.IsZero() {
		input.CreatedAt = now
	}
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "User", validation.OpCreate, userValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, userInsertQuery, input.ID, input.Username, input.Email, input.PasswordHash, input.DisplayName, input.Bio, input.AvatarURL, input.WebsiteURL, input.LastLoginAt, input.CreatedAt, input.UpdatedAt)
	out := new(User)
	if err := row.Scan(&out.ID, &out.Username, &out.Email, &out.PasswordHash, &out.DisplayName, &out.Bio, &out.AvatarURL, &out.WebsiteURL, &out.LastLoginAt, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("User", out.ID), out)
	}
	return out, nil
}

func (c *UserClient) BulkCreate(ctx context.Context, inputs []*User) ([]*User, error) {
	if len(inputs) == 0 {
		return []*User{}, nil
	}
	rowsSpec := make([][]any, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		now := time.Now().UTC()
		if input.ID == "" {
			v, err := id.NewV7()
			if err != nil {
				return nil, err
			}
			input.ID = v
		}
		if input.CreatedAt.IsZero() {
			input.CreatedAt = now
		}
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "User", validation.OpCreate, userValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := []any{input.ID, input.Username, input.Email, input.PasswordHash, input.DisplayName, input.Bio, input.AvatarURL, input.WebsiteURL, input.LastLoginAt, input.CreatedAt, input.UpdatedAt}
		rowsSpec = append(rowsSpec, row)
	}
	spec := runtime.BulkInsertSpec{
		Table:     "users",
		Columns:   []string{"id", "username", "email", "password_hash", "display_name", "bio", "avatar_url", "website_url", "last_login_at", "created_at", "updated_at"},
		Returning: []string{"id", "username", "email", "password_hash", "display_name", "bio", "avatar_url", "website_url", "last_login_at", "created_at", "updated_at"},
		Rows:      rowsSpec,
	}
	sql, args, err := runtime.BuildBulkInsertSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var created []*User
	for rows.Next() {
		item := new(User)
		if err := rows.Scan(&item.ID, &item.Username, &item.Email, &item.PasswordHash, &item.DisplayName, &item.Bio, &item.AvatarURL, &item.WebsiteURL, &item.LastLoginAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		created = append(created, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("User", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return created, nil
}

func (c *UserClient) ByID(ctx context.Context, id string) (*User, error) {
	var cachedKey string
	if c.cache != nil {
		cachedKey = makeCacheKey("User", id)
		if value, ok, err := c.cache.Get(ctx, cachedKey); err != nil {
			return nil, err
		} else if ok {
			if entity, ok := value.(*User); ok {
				return entity, nil
			}
		}
	}
	row := c.db.Pool.QueryRow(ctx, userSelectQuery, id)
	out := new(User)
	if err := row.Scan(&out.ID, &out.Username, &out.Email, &out.PasswordHash, &out.DisplayName, &out.Bio, &out.AvatarURL, &out.WebsiteURL, &out.LastLoginAt, &out.CreatedAt, &out.UpdatedAt); err != nil {
		if errors.Is(err, pgx.ErrNoRows) {
			return nil, nil
		}
		return nil, err
	}
	if c.cache != nil {
		cachedKey = makeCacheKey("User", out.ID)
		_ = c.cache.Set(ctx, cachedKey, out)
	}
	return out, nil
}

func (c *UserClient) List(ctx context.Context, limit, offset int) ([]*User, error) {
	if limit <= 0 {
		limit = 20
	}
	if offset < 0 {
		offset = 0
	}
	rows, err := c.db.Pool.Query(ctx, userListQuery, limit, offset)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*User
	for rows.Next() {
		item := new(User)
		if err := rows.Scan(&item.ID, &item.Username, &item.Email, &item.PasswordHash, &item.DisplayName, &item.Bio, &item.AvatarURL, &item.WebsiteURL, &item.LastLoginAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (c *UserClient) Count(ctx context.Context) (int, error) {
	row := c.db.Pool.QueryRow(ctx, userCountQuery)
	var total int
	if err := row.Scan(&total); err != nil {
		return 0, err
	}
	return total, nil
}

func (c *UserClient) Update(ctx context.Context, input *User) (*User, error) {
	if input == nil {
		return nil, errors.New("input cannot be nil")
	}
	if input.ID == "" {
		return nil, errors.New("id is required")
	}
	now := time.Now().UTC()
	input.UpdatedAt = now
	if err := ValidationRegistry.Validate(ctx, "User", validation.OpUpdate, userValidationRecord(input), input); err != nil {
		return nil, err
	}
	row := c.db.Pool.QueryRow(ctx, userUpdateQuery, input.Username, input.Email, input.PasswordHash, input.DisplayName, input.Bio, input.AvatarURL, input.WebsiteURL, input.LastLoginAt, input.UpdatedAt, input.ID)
	out := new(User)
	if err := row.Scan(&out.ID, &out.Username, &out.Email, &out.PasswordHash, &out.DisplayName, &out.Bio, &out.AvatarURL, &out.WebsiteURL, &out.LastLoginAt, &out.CreatedAt, &out.UpdatedAt); err != nil {
		return nil, err
	}
	if c.cache != nil {
		_ = c.cache.Set(ctx, makeCacheKey("User", out.ID), out)
	}
	return out, nil
}

func (c *UserClient) BulkUpdate(ctx context.Context, inputs []*User) ([]*User, error) {
	if len(inputs) == 0 {
		return []*User{}, nil
	}
	specs := make([]runtime.BulkUpdateRow, 0, len(inputs))
	for _, input := range inputs {
		if input == nil {
			return nil, errors.New("input cannot be nil")
		}
		if input.ID == "" {
			return nil, errors.New("id is required")
		}
		now := time.Now().UTC()
		input.UpdatedAt = now
		if err := ValidationRegistry.Validate(ctx, "User", validation.OpUpdate, userValidationRecord(input), input); err != nil {
			return nil, err
		}
		row := runtime.BulkUpdateRow{
			Primary: input.ID,
			Values:  []any{input.Username, input.Email, input.PasswordHash, input.DisplayName, input.Bio, input.AvatarURL, input.WebsiteURL, input.LastLoginAt, input.UpdatedAt},
		}
		specs = append(specs, row)
	}
	spec := runtime.BulkUpdateSpec{
		Table:         "users",
		PrimaryColumn: "id",
		Columns:       []string{"username", "email", "password_hash", "display_name", "bio", "avatar_url", "website_url", "last_login_at", "updated_at"},
		Returning:     []string{"id", "username", "email", "password_hash", "display_name", "bio", "avatar_url", "website_url", "last_login_at", "created_at", "updated_at"},
		Rows:          specs,
	}
	sql, args, err := runtime.BuildBulkUpdateSQL(spec)
	if err != nil {
		return nil, err
	}
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var updated []*User
	for rows.Next() {
		item := new(User)
		if err := rows.Scan(&item.ID, &item.Username, &item.Email, &item.PasswordHash, &item.DisplayName, &item.Bio, &item.AvatarURL, &item.WebsiteURL, &item.LastLoginAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		updated = append(updated, item)
		if c.cache != nil {
			_ = c.cache.Set(ctx, makeCacheKey("User", item.ID), item)
		}
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return updated, nil
}

func (c *UserClient) Delete(ctx context.Context, id string) error {
	if _, err := c.db.Pool.Exec(ctx, userDeleteQuery, id); err != nil {
		return err
	}
	if c.cache != nil {
		_ = c.cache.Delete(ctx, makeCacheKey("User", id))
	}
	return nil
}

func (c *UserClient) BulkDelete(ctx context.Context, ids []string) (int64, error) {
	if len(ids) == 0 {
		return 0, nil
	}
	spec := runtime.BulkDeleteSpec{
		Table:         "users",
		PrimaryColumn: "id",
		IDs:           make([]any, len(ids)),
	}
	for i, id := range ids {
		spec.IDs[i] = id
	}
	sql, args, err := runtime.BuildBulkDeleteSQL(spec)
	if err != nil {
		return 0, err
	}
	tag, err := c.db.Pool.Exec(ctx, sql, args...)
	if err != nil {
		return 0, err
	}
	if c.cache != nil {
		for _, id := range ids {
			_ = c.cache.Delete(ctx, makeCacheKey("User", id))
		}
	}
	return int64(tag.RowsAffected()), nil
}

type UserQuery struct {
	db           *pg.DB
	predicates   []runtime.Predicate
	orders       []runtime.Order
	limit        *int
	offset       int
	defaultLimit int
	maxLimit     int
}

func (c *UserClient) Query() *UserQuery {
	return &UserQuery{db: c.db, defaultLimit: 50, maxLimit: 200}
}

func (q *UserQuery) Limit(n int) *UserQuery {
	if n <= 0 {
		q.limit = nil
		return q
	}
	q.limit = &n
	return q
}

func (q *UserQuery) Offset(n int) *UserQuery {
	if n < 0 {
		return q
	}
	q.offset = n
	return q
}

func (q *UserQuery) WhereIDEq(value string) *UserQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "id", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *UserQuery) WhereUsernameEq(value string) *UserQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "username", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *UserQuery) WhereEmailEq(value string) *UserQuery {
	q.predicates = append(q.predicates, runtime.Predicate{Column: "email", Operator: runtime.OpEqual, Value: value})
	return q
}

func (q *UserQuery) OrderByCreatedAtDesc() *UserQuery {
	q.orders = append(q.orders, runtime.Order{Column: "created_at", Direction: runtime.SortDesc})
	return q
}

func (q *UserQuery) OrderByUsernameAsc() *UserQuery {
	q.orders = append(q.orders, runtime.Order{Column: "username", Direction: runtime.SortAsc})
	return q
}

func (q *UserQuery) All(ctx context.Context) ([]*User, error) {
	spec := runtime.SelectSpec{
		Table:      "users",
		Columns:    []string{"id", "username", "email", "password_hash", "display_name", "bio", "avatar_url", "website_url", "last_login_at", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	defer rows.Close()
	var result []*User
	for rows.Next() {
		item := new(User)
		if err := rows.Scan(&item.ID, &item.Username, &item.Email, &item.PasswordHash, &item.DisplayName, &item.Bio, &item.AvatarURL, &item.WebsiteURL, &item.LastLoginAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		result = append(result, item)
	}
	if err := rows.Err(); err != nil {
		return nil, err
	}
	return result, nil
}

func (q *UserQuery) Stream(ctx context.Context) (*runtime.Stream[*User], error) {
	spec := runtime.SelectSpec{
		Table:      "users",
		Columns:    []string{"id", "username", "email", "password_hash", "display_name", "bio", "avatar_url", "website_url", "last_login_at", "created_at", "updated_at"},
		Predicates: q.predicates,
		Orders:     q.orders,
		Limit:      q.effectiveLimit(),
		Offset:     q.offset,
	}
	rows, err := q.db.Select(ctx, spec)
	if err != nil {
		return nil, err
	}
	stream := runtime.NewStream[*User](rows, func(rows pgx.Rows) (*User, error) {
		item := new(User)
		if err := rows.Scan(&item.ID, &item.Username, &item.Email, &item.PasswordHash, &item.DisplayName, &item.Bio, &item.AvatarURL, &item.WebsiteURL, &item.LastLoginAt, &item.CreatedAt, &item.UpdatedAt); err != nil {
			return nil, err
		}
		return item, nil
	})
	return stream, nil
}

func (q *UserQuery) First(ctx context.Context) (*User, error) {
	clone := q.clone()
	one := 1
	clone.limit = &one
	items, err := clone.All(ctx)
	if err != nil {
		return nil, err
	}
	if len(items) == 0 {
		return nil, nil
	}
	return items[0], nil
}

func (q *UserQuery) Count(ctx context.Context) (int, error) {
	spec := runtime.AggregateSpec{
		Table:      "users",
		Predicates: q.predicates,
		Aggregate:  runtime.Aggregate{Func: runtime.AggCount, Column: "*"},
	}
	row := q.db.Aggregate(ctx, spec)
	var out int
	if err := row.Scan(&out); err != nil {
		return out, err
	}
	return out, nil
}

func (q *UserQuery) clone() *UserQuery {
	cp := *q
	if len(q.predicates) > 0 {
		cp.predicates = append([]runtime.Predicate(nil), q.predicates...)
	}
	if len(q.orders) > 0 {
		cp.orders = append([]runtime.Order(nil), q.orders...)
	}
	if q.limit != nil {
		limit := *q.limit
		cp.limit = &limit
	}
	return &cp
}

func (q *UserQuery) effectiveLimit() int {
	if q.limit != nil {
		limit := *q.limit
		if q.maxLimit > 0 && limit > q.maxLimit {
			return q.maxLimit
		}
		return limit
	}
	limit := q.defaultLimit
	if limit <= 0 && q.maxLimit > 0 {
		return q.maxLimit
	}
	if q.maxLimit > 0 && limit > q.maxLimit {
		return q.maxLimit
	}
	return limit
}

const userRolesRelationQuery = `SELECT id, name, slug, description, capabilities, created_at, updated_at, jt.user_id FROM roles AS t JOIN user_roles AS jt ON t.id = jt.role_id WHERE jt.user_id IN (%s)`

func (c *UserClient) LoadRoles(ctx context.Context, parents ...*User) error {
	if len(parents) == 0 {
		return nil
	}
	type keyType = string
	keys := make([]keyType, 0, len(parents))
	seen := make(map[keyType]struct{}, len(parents))
	buckets := make(map[keyType][]*User, len(parents))
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		key := parent.ID
		if isZero(key) {
			edges := ensureUserEdges(parent)
			if edges.Roles == nil {
				edges.Roles = []*Role{}
			}
			edges.markLoaded("roles")
			continue
		}
		if _, ok := seen[key]; !ok {
			seen[key] = struct{}{}
			keys = append(keys, key)
		}
		buckets[key] = append(buckets[key], parent)
	}
	if len(keys) == 0 {
		for _, parent := range parents {
			if parent == nil {
				continue
			}
			edges := ensureUserEdges(parent)
			if edges.Roles == nil {
				edges.Roles = []*Role{}
			}
			edges.markLoaded("roles")
		}
		return nil
	}
	sql, args := buildInQuery(userRolesRelationQuery, keys)
	rows, err := c.db.Pool.Query(ctx, sql, args...)
	if err != nil {
		return err
	}
	defer rows.Close()
	for rows.Next() {
		item := new(Role)
		var owner keyType
		if err := rows.Scan(&item.ID, &item.Name, &item.Slug, &item.Description, &item.Capabilities, &item.CreatedAt, &item.UpdatedAt, &owner); err != nil {
			return err
		}
		parents, ok := buckets[owner]
		if !ok {
			continue
		}
		for _, parent := range parents {
			edges := ensureUserEdges(parent)
			edges.Roles = append(edges.Roles, item)
		}
	}
	if err := rows.Err(); err != nil {
		return err
	}
	for _, parent := range parents {
		if parent == nil {
			continue
		}
		edges := ensureUserEdges(parent)
		if edges.Roles == nil {
			edges.Roles = []*Role{}
		}
		edges.markLoaded("roles")
	}
	return nil
}

func categoryValidationRecord(input *Category) validation.Record {
	if input == nil {
		return nil
	}
	return validation.Record{
		"ID":          input.ID,
		"Name":        input.Name,
		"Slug":        input.Slug,
		"Description": input.Description,
		"ParentID":    input.ParentID,
		"CreatedAt":   input.CreatedAt,
		"UpdatedAt":   input.UpdatedAt,
	}
}

func commentValidationRecord(input *Comment) validation.Record {
	if input == nil {
		return nil
	}
	return validation.Record{
		"ID":          input.ID,
		"PostID":      input.PostID,
		"AuthorID":    input.AuthorID,
		"ParentID":    input.ParentID,
		"AuthorName":  input.AuthorName,
		"AuthorEmail": input.AuthorEmail,
		"AuthorURL":   input.AuthorURL,
		"Content":     input.Content,
		"Status":      input.Status,
		"SubmittedAt": input.SubmittedAt,
		"PublishedAt": input.PublishedAt,
		"UpdatedAt":   input.UpdatedAt,
	}
}

func mediaValidationRecord(input *Media) validation.Record {
	if input == nil {
		return nil
	}
	return validation.Record{
		"ID":            input.ID,
		"UploadedByID":  input.UploadedByID,
		"FileName":      input.FileName,
		"MimeType":      input.MimeType,
		"StorageKey":    input.StorageKey,
		"URL":           input.URL,
		"Title":         input.Title,
		"AltText":       input.AltText,
		"Caption":       input.Caption,
		"Description":   input.Description,
		"FileSizeBytes": input.FileSizeBytes,
		"Metadata":      input.Metadata,
		"CreatedAt":     input.CreatedAt,
		"UpdatedAt":     input.UpdatedAt,
	}
}

func optionValidationRecord(input *Option) validation.Record {
	if input == nil {
		return nil
	}
	return validation.Record{
		"ID":        input.ID,
		"Name":      input.Name,
		"Value":     input.Value,
		"Autoload":  input.Autoload,
		"CreatedAt": input.CreatedAt,
		"UpdatedAt": input.UpdatedAt,
	}
}

func postValidationRecord(input *Post) validation.Record {
	if input == nil {
		return nil
	}
	return validation.Record{
		"ID":              input.ID,
		"AuthorID":        input.AuthorID,
		"FeaturedMediaID": input.FeaturedMediaID,
		"Title":           input.Title,
		"Slug":            input.Slug,
		"Status":          input.Status,
		"Type":            input.Type,
		"Excerpt":         input.Excerpt,
		"Content":         input.Content,
		"Seo":             input.Seo,
		"PublishedAt":     input.PublishedAt,
		"CreatedAt":       input.CreatedAt,
		"UpdatedAt":       input.UpdatedAt,
	}
}

func roleValidationRecord(input *Role) validation.Record {
	if input == nil {
		return nil
	}
	return validation.Record{
		"ID":           input.ID,
		"Name":         input.Name,
		"Slug":         input.Slug,
		"Description":  input.Description,
		"Capabilities": input.Capabilities,
		"CreatedAt":    input.CreatedAt,
		"UpdatedAt":    input.UpdatedAt,
	}
}

func tagValidationRecord(input *Tag) validation.Record {
	if input == nil {
		return nil
	}
	return validation.Record{
		"ID":          input.ID,
		"Name":        input.Name,
		"Slug":        input.Slug,
		"Description": input.Description,
		"CreatedAt":   input.CreatedAt,
		"UpdatedAt":   input.UpdatedAt,
	}
}

func userValidationRecord(input *User) validation.Record {
	if input == nil {
		return nil
	}
	return validation.Record{
		"ID":           input.ID,
		"Username":     input.Username,
		"Email":        input.Email,
		"PasswordHash": input.PasswordHash,
		"DisplayName":  input.DisplayName,
		"Bio":          input.Bio,
		"AvatarURL":    input.AvatarURL,
		"WebsiteURL":   input.WebsiteURL,
		"LastLoginAt":  input.LastLoginAt,
		"CreatedAt":    input.CreatedAt,
		"UpdatedAt":    input.UpdatedAt,
	}
}

func buildInQuery[T any](base string, values []T) (string, []any) {
	if len(values) == 0 {
		return base, nil
	}
	placeholders := make([]string, len(values))
	args := make([]any, len(values))
	for i := range values {
		placeholders[i] = fmt.Sprintf("$%d", i+1)
		args[i] = values[i]
	}
	return fmt.Sprintf(base, strings.Join(placeholders, ", ")), args
}

func isZero[T comparable](v T) bool {
	var zero T
	return v == zero
}
